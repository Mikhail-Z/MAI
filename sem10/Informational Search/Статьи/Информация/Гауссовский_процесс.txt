В теории вероятностей и статистике гауссовский процесс - это стохастический процесс (совокупность случайных величин, индексированных некоторым параметром, чаще всего временем или координатами), такой что любой конечный набор этих случайных величин имеет многомерное нормальное распределение, то есть любая конечная линейная комбинация из них нормально распределена. Распределение гауссовского процесса – это совместное распределение всех его случайных величин и, в силу чего, является распределением функций с непрерывной областью определения.
Если рассматривать гауссовский процесс как способ решения задач машинного обучения, то используется ленивое обучение и мера подобия между точками (функция ядра) для получения прогноза значения невидимой точки из обучающей выборки. В понятие прогноза, помимо самой оценки точки, входит информация о неопределенности — одномерное гауссовское распределение.Для вычисления прогнозов некоторых функций ядра используют метод матричной алгебры, кригинг. 
Гауссовский процесс назван так в честь Карла Фридриха Гаусса, поскольку в его основе лежит понятие гауссовского распределения (нормального распределения). Гауссовский процесс может рассматриваться как бесконечномерное обобщение многомерных нормальных распределений. Эти процессы применяются в статистическом моделировании; в частности используются свойства нормальности. Например, если случайный процесс моделируется как гауссовский, то распределения различных производных величин, такие как среднее значение процесса в течение определенного промежутка времени и погрешность его оценки с использованием выборки значений, могут быть получены явно.

Определение
Случайный процесс с непрерывным временем является гауссовским тогда и только тогда, когда для любого конечного множества индексов 
  
    
      
        
          t
          
            1
          
        
        ,
        …
        ,
        
          t
          
            k
          
        
      
    
    {\displaystyle t_{1},\ldots ,t_{k}}
   из множества индексов 
  
    
      
        T
      
    
    {\displaystyle T}
  

  
    
      
        
          
            X
          
          
            
              t
              
                1
              
            
            ,
            …
            ,
            
              t
              
                k
              
            
          
        
        =
        (
        
          
            X
          
          
            
              t
              
                1
              
            
          
        
        ,
        …
        ,
        
          
            X
          
          
            
              t
              
                k
              
            
          
        
        )
      
    
    {\displaystyle \mathbf {X} _{t_{1},\ldots ,t_{k}}=(\mathbf {X} _{t_{1}},\ldots ,\mathbf {X} _{t_{k}})}
  - многомерная гауссовская случайная величина. То же самое, что и всякая линейная комбинация 
  
    
      
        (
        
          
            X
          
          
            
              t
              
                1
              
            
          
        
        ,
        …
        ,
        
          
            X
          
          
            
              t
              
                k
              
            
          
        
        )
      
    
    {\displaystyle (\mathbf {X} _{t_{1}},\ldots ,\mathbf {X} _{t_{k}})}
   имеет одномерное нормальное (гауссовское) распределение. Используя характеристические функции случайных величин, свойство Гаусса можно сформулировать следующим образом: 
  
    
      
        
          {
          
            
              X
              
                t
              
            
            ;
            t
            ∈
            T
          
          }
        
      
    
    {\displaystyle \left\{X_{t};t\in T\right\}}
   - гауссовское тогда и только тогда, когда для любого конечного множества индексов 
  
    
      
        
          t
          
            1
          
        
        ,
        …
        ,
        
          t
          
            k
          
        
      
    
    {\displaystyle t_{1},\ldots ,t_{k}}
  , существуют вещественные значения 
  
    
      
        
          σ
          
            ℓ
            j
          
        
      
    
    {\displaystyle \sigma _{\ell j}}
  , 
  
    
      
        
          μ
          
            ℓ
          
        
      
    
    {\displaystyle \mu _{\ell }}
   где 
  
    
      
        
          σ
          
            j
            j
          
        
        >
        0
      
    
    {\displaystyle \sigma _{jj}>0}
   такие, что для всех  
  
    
      
        
          s
          
            1
          
        
        ,
        
          s
          
            2
          
        
        ,
        …
        ,
        
          s
          
            k
          
        
        ∈
        
          R
        
      
    
    {\displaystyle s_{1},s_{2},\ldots ,s_{k}\in \mathbb {R} }
   выполнено равенство

  
    
      
        E
        ⁡
        
          (
          
            exp
            ⁡
            
              (
              
                i
                 
                
                  ∑
                  
                    ℓ
                    =
                    1
                  
                  
                    k
                  
                
                
                  s
                  
                    ℓ
                  
                
                 
                
                  
                    X
                  
                  
                    
                      t
                      
                        ℓ
                      
                    
                  
                
              
              )
            
          
          )
        
        =
        exp
        ⁡
        
          (
          
            −
            
              
                1
                2
              
            
            
            
              ∑
              
                ℓ
                ,
                j
              
            
            
              σ
              
                ℓ
                j
              
            
            
              s
              
                ℓ
              
            
            
              s
              
                j
              
            
            +
            i
            
              ∑
              
                ℓ
              
            
            
              μ
              
                ℓ
              
            
            
              s
              
                ℓ
              
            
          
          )
        
        .
      
    
    {\displaystyle \operatorname {E} \left(\exp \left(i\ \sum _{\ell =1}^{k}s_{\ell }\ \mathbf {X} _{t_{\ell }}\right)\right)=\exp \left(-{\frac {1}{2}}\,\sum _{\ell ,j}\sigma _{\ell j}s_{\ell }s_{j}+i\sum _{\ell }\mu _{\ell }s_{\ell }\right).}
  Где 
  
    
      
        i
      
    
    {\displaystyle i}
   - мнимая единица.
Числа 
  
    
      
        
          σ
          
            ℓ
            j
          
        
      
    
    {\displaystyle \sigma _{\ell j}}
   и 
  
    
      
        
          μ
          
            ℓ
          
        
      
    
    {\displaystyle \mu _{\ell }}
   - ковариации и средние значения переменных в процессах соответственно.

Ковариационные функции
Главная особенность гауссовских процессов - они могут быть полностью определены второй порядковой статистикой. Следовательно, ковариационная функция полностью определяет поведение процесса, если математическое ожидание гауссовского процесса равно нулю. Важно отметить, что неотрицательная определенность функции делает возможным ее спектральное разложение при помощи разложения Карунена - Лоэва. Через ковариационную функцию можно определить стационарность, изотропию, гладкость и периодичность процесса.Стационарность выражает поведение процесса относительно расстояния между любыми двумя точками 
  
    
      
        x
      
    
    {\displaystyle x}
   и 
  
    
      
        
          x
          ′
        
      
    
    {\displaystyle x'}
  . Если процесс стационарный, то он зависит от взаимного расположения своих точек, расстояния между ними, 
  
    
      
        x
        −
        
          x
          ′
        
      
    
    {\displaystyle x-x'}
  , в ином случае, он нестационарный, то есть зависит от фактического положения точек 
  
    
      
        x
      
    
    {\displaystyle x}
   и 
  
    
      
        
          x
          ′
        
      
    
    {\displaystyle x'}
  . Примером может послужить частный случай процесса Орнштейна-Уленбека, процесс броуновского движения: он является стационарным.
Если процесс зависит только от 
  
    
      
        
          |
        
        x
        −
        
          x
          ′
        
        
          |
        
      
    
    {\displaystyle |x-x'|}
  , евклидова расстояния (не направления) между 
  
    
      
        x
      
    
    {\displaystyle x}
   и 
  
    
      
        
          x
          ′
        
      
    
    {\displaystyle x'}
  , то процесс считается изотропным. Стационарный и изотропный процесс называют однородным; на практике свойства стационарности и изотропии отражают различия(или, скорее, их отсутствие) в поведении процесса с учетом положения наблюдателя.
Суть гауссовских процессов заключается в получении априорных распределений вероятности, гладкость которых зависит от взятой ковариационной функции. Если мы ожидаем, что для "лежащих близко" входных точек 
  
    
      
        x
      
    
    {\displaystyle x}
   и 
  
    
      
        
          x
          ′
        
      
    
    {\displaystyle x'}
   соответствующие им выходные точки 
  
    
      
        y
      
    
    {\displaystyle y}
   и 
  
    
      
        
          y
          ′
        
      
    
    {\displaystyle y'}
   также "лежат близко", тогда присутствует предположение о непрерывности функции. Если мы хотим допустить значительное смещение, то нужно выбрать более грубую ковариационную функцию. В качестве примеров крайнего поведения можно привести ковариационную функцию Орнштейна-Уленбека и квадратичную экспоненциальную функцию, где первая не дифференцируема нигде, а последняя бесконечно дифференцируема.
Под периодичностью понимается индуцирование периодических закономерностей в поведении процесса. Формально это достигается путем отображения входного значения 
  
    
      
        x
      
    
    {\displaystyle x}
   на двумерный вектор

  
    
      
        u
        (
        x
        )
        =
        (
        c
        o
        s
        (
        x
        )
        ,
        s
        i
        n
        (
        x
        )
        )
        .
      
    
    {\displaystyle u(x)=(cos(x),sin(x)).}

Обычные ковариационные функции
Существует ряд общих ковариационных функций:
Константа: 
  
    
      
        
          K
          
            C
          
        
        (
        x
        ,
        
          x
          ′
        
        )
        =
        C
      
    
    {\displaystyle K_{\operatorname {C} }(x,x')=C}
  
Линейная функция: 
  
    
      
        
          K
          
            L
          
        
        (
        x
        ,
        
          x
          ′
        
        )
        =
        
          x
          
            T
          
        
        
          x
          ′
        
      
    
    {\displaystyle K_{\operatorname {L} }(x,x')=x^{T}x'}
  
Гауссовский шум: 
  
    
      
        
          K
          
            GN
          
        
        (
        x
        ,
        
          x
          ′
        
        )
        =
        
          σ
          
            2
          
        
        
          δ
          
            x
            ,
            
              x
              ′
            
          
        
      
    
    {\displaystyle K_{\operatorname {GN} }(x,x')=\sigma ^{2}\delta _{x,x'}}
  
Квадратичная экспоненциальная функция: 
  
    
      
        
          K
          
            SE
          
        
        (
        x
        ,
        
          x
          ′
        
        )
        =
        exp
        ⁡
        
          
            (
          
        
        −
        
          
            
              ‖
              d
              
                ‖
                
                  2
                
              
            
            
              2
              
                ℓ
                
                  2
                
              
            
          
        
        
          
            )
          
        
      
    
    {\displaystyle K_{\operatorname {SE} }(x,x')=\exp {\Big (}-{\frac {\|d\|^{2}}{2\ell ^{2}}}{\Big )}}
  
Функция Орнштейна-Уленбека: 
  
    
      
        
          K
          
            OU
          
        
        (
        x
        ,
        
          x
          ′
        
        )
        =
        exp
        ⁡
        
          (
          
            −
            
              
                
                  
                    |
                  
                  d
                  
                    |
                  
                
                ℓ
              
            
          
          )
        
      
    
    {\displaystyle K_{\operatorname {OU} }(x,x')=\exp \left(-{\frac {|d|}{\ell }}\right)}
  
Matérn: 
  
    
      
        
          K
          
            Matern
          
        
        (
        x
        ,
        
          x
          ′
        
        )
        =
        
          
            
              2
              
                1
                −
                ν
              
            
            
              Γ
              (
              ν
              )
            
          
        
        
          
            (
          
        
        
          
            
              
                
                  2
                  ν
                
              
              
                |
              
              d
              
                |
              
            
            ℓ
          
        
        
          
            
              )
            
          
          
            ν
          
        
        
          K
          
            ν
          
        
        
          
            (
          
        
        
          
            
              
                
                  2
                  ν
                
              
              
                |
              
              d
              
                |
              
            
            ℓ
          
        
        
          
            )
          
        
      
    
    {\displaystyle K_{\operatorname {Matern} }(x,x')={\frac {2^{1-\nu }}{\Gamma (\nu )}}{\Big (}{\frac {{\sqrt {2\nu }}|d|}{\ell }}{\Big )}^{\nu }K_{\nu }{\Big (}{\frac {{\sqrt {2\nu }}|d|}{\ell }}{\Big )}}
  
Периодическая функция: 
  
    
      
        
          K
          
            P
          
        
        (
        x
        ,
        
          x
          ′
        
        )
        =
        exp
        ⁡
        
          (
          
            −
            
              
                
                  2
                  
                    sin
                    
                      2
                    
                  
                  ⁡
                  
                    (
                    
                      
                        d
                        2
                      
                    
                    )
                  
                
                
                  ℓ
                  
                    2
                  
                
              
            
          
          )
        
      
    
    {\displaystyle K_{\operatorname {P} }(x,x')=\exp \left(-{\frac {2\sin ^{2}\left({\frac {d}{2}}\right)}{\ell ^{2}}}\right)}
  
Рациональная квадратичная функция: 
  
    
      
        
          K
          
            RQ
          
        
        (
        x
        ,
        
          x
          ′
        
        )
        =
        (
        1
        +
        
          |
        
        d
        
          
            |
          
          
            2
          
        
        
          )
          
            −
            α
          
        
        ,
        
        α
        ≥
        0
      
    
    {\displaystyle K_{\operatorname {RQ} }(x,x')=(1+|d|^{2})^{-\alpha },\quad \alpha \geq 0}
  Здесь 
  
    
      
        d
        =
        x
        −
        
          x
          ′
        
      
    
    {\displaystyle d=x-x'}
  . Параметр 
  
    
      
        ℓ
      
    
    {\displaystyle \ell }
   является характеристикой масштаба длины процесса (практически, «насколько близко» две точки 
  
    
      
        x
      
    
    {\displaystyle x}
   и 
  
    
      
        
          x
          ′
        
      
    
    {\displaystyle x'}
   должны быть, чтобы значительно влиять друг на друга), 
  
    
      
        δ
      
    
    {\displaystyle \delta }
   - это символ Кронекера и 
  
    
      
        σ
      
    
    {\displaystyle \sigma }
   - среднеквадратическое отклонение колебаний шума. Кроме того, 
  
    
      
        
          K
          
            ν
          
        
      
    
    {\displaystyle K_{\nu }}
   является модифицированной функцией Бесселя 
  
    
      
        ν
      
    
    {\displaystyle \nu }
   и 
  
    
      
        Γ
        (
        ν
        )
      
    
    {\displaystyle \Gamma (\nu )}
   - это гамма-функция, вычисленная по 
  
    
      
        ν
      
    
    {\displaystyle \nu }
  . Важно отметить, что сложную ковариационную функцию можно определить как линейную комбинацию других более простых ковариационных функций затем, чтобы объединить различную информацию о имеющихся наборах данных.
Очевидно, что полученные результаты зависят от значений гиперпараметров 
  
    
      
        θ
      
    
    {\displaystyle \theta }
   (например, 
  
    
      
        ℓ
      
    
    {\displaystyle \ell }
   и 
  
    
      
        σ
      
    
    {\displaystyle \sigma }
  ), определяющих поведение модели.

Броуновское движение как интеграл гауссовских процессов
Винеровский процесс (так называемое броуновское движение) является интегралом гауссовского процесса белого шума. Он не стационарен, однако имеет стационарные приращения.
Процесс Орнштейна-Уленбека - это стационарный гауссовский процесс.
Броуновский мост (подобный процессу Орнштейна-Уленбека) является примером гауссовского процесса, приращения которого не являются независимыми.
Дробное броуновское движение является гауссовским процессом, ковариационная функция которого является обобщением функции винеровского процесса.

Приложения
Гауссовский процесс может быть использован как априорное распределение вероятностей функций в байесовском выводе. Для любого множества из N точек в нужной области функций возьмите многомерное гауссовское распределение, ковариационный матричный параметр которого является определителем Грама взятых N точек с некоторым желаемым ядром, и выборку из этого распределения.
Вывод непрерывных значений на основе гауссовского процесса, определяемого предыдущими ковариациями, известен как кригинг (регрессия на основе гауссовского процесса). Поэтому, гауссовские процессы полезны в качестве мощного нелинейного многомерного инструмента интерполяции. Регрессия на основе гауссовского процесса может быть дополнительно расширена для решения задач обучения как с учителем, так и без (самообучение).

Прогноз гауссовского процесса или кригинг
Когда речь идёт об основной проблеме регрессии на основе гауссовского процесса (кригинге), предполагается, что для гауссовского процесса 
  
    
      
        f
      
    
    {\displaystyle f}
  , наблюдаемого в координатах 
  
    
      
        x
      
    
    {\displaystyle x}
  , вектор значений 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
   является всего лишь одной из выборок многомерного гауссовского распределения, размерность которого равна числу наблюдаемых координат 
  
    
      
        
          |
        
        x
        
          |
        
      
    
    {\displaystyle |x|}
  . Следовательно, согласно допущению о нулевом распределении, 
  
    
      
        f
        (
        x
        )
        ∼
        N
        (
        0
        ,
        K
        (
        θ
        ,
        x
        ,
        
          x
          ′
        
        )
        )
      
    
    {\displaystyle f(x)\sim N(0,K(\theta ,x,x'))}
  , где 
  
    
      
        K
        (
        θ
        ,
        x
        ,
        
          x
          ′
        
        )
      
    
    {\displaystyle K(\theta ,x,x')}
   - ковариационная матрица между всеми возможными парами 
  
    
      
        (
        x
        ,
        
          x
          ′
        
        )
      
    
    {\displaystyle (x,x')}
   для заданного множества гиперпараметров 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  . Таким образом, логарифм предельной вероятности равен:

  
    
      
        log
        ⁡
        p
        (
        f
        (
        x
        )
        
          |
        
        θ
        ,
        x
        )
        =
        −
        
          
            1
            2
          
        
        f
        (
        x
        
          )
          
            T
          
        
        K
        (
        θ
        ,
        x
        ,
        
          x
          ′
        
        
          )
          
            −
            1
          
        
        f
        (
        x
        )
        −
        
          
            1
            2
          
        
        log
        ⁡
        det
        (
        K
        (
        θ
        ,
        x
        ,
        
          x
          ′
        
        )
        )
        −
        
          
            
              
                |
              
              x
              
                |
              
            
            2
          
        
        log
        ⁡
        2
        π
      
    
    {\displaystyle \log p(f(x)|\theta ,x)=-{\frac {1}{2}}f(x)^{T}K(\theta ,x,x')^{-1}f(x)-{\frac {1}{2}}\log \det(K(\theta ,x,x'))-{\frac {|x|}{2}}\log 2\pi }
  и максимизация этой предельной вероятности по отношению к 
  
    
      
        θ
      
    
    {\displaystyle \theta }
   даёт полную характеристику гауссовского процесса 
  
    
      
        f
      
    
    {\displaystyle f}
  . Можно отметить, что первое выражение зависит от неспособности модели соответствовать наблюдаемым значениям, а второе выражение прямо пропорционально сложности модели. Указав 
  
    
      
        θ
      
    
    {\displaystyle \theta }
   и сделав прогноз о ненаблюдаемых значениях 
  
    
      
        f
        (
        
          x
          
            ∗
          
        
        )
      
    
    {\displaystyle f(x^{*})}
   в координатах 
  
    
      
        
          x
          
            ∗
          
        
      
    
    {\displaystyle x^{*}}
  , останется сделать график выборок из прогностического распределения 
  
    
      
        p
        (
        
          y
          
            ∗
          
        
        ∣
        
          x
          
            ∗
          
        
        ,
        f
        (
        x
        )
        ,
        x
        )
        =
        N
        (
        
          y
          
            ∗
          
        
        ∣
        A
        ,
        B
        )
      
    
    {\displaystyle p(y^{*}\mid x^{*},f(x),x)=N(y^{*}\mid A,B)}
  , где последующая средняя оценка 
  
    
      
        A
      
    
    {\displaystyle A}
   определяется как

  
    
      
        A
        =
        K
        (
        θ
        ,
        
          x
          
            ∗
          
        
        ,
        x
        )
        K
        (
        θ
        ,
        x
        ,
        
          x
          ′
        
        
          )
          
            −
            1
          
        
        f
        (
        x
        )
      
    
    {\displaystyle A=K(\theta ,x^{*},x)K(\theta ,x,x')^{-1}f(x)}
  и последующая оценка дисперсии B определяется как

  
    
      
        B
        =
        K
        (
        θ
        ,
        
          x
          
            ∗
          
        
        ,
        
          x
          
            ∗
          
        
        )
        −
        K
        (
        θ
        ,
        
          x
          
            ∗
          
        
        ,
        x
        )
        K
        (
        θ
        ,
        x
        ,
        
          x
          ′
        
        
          )
          
            −
            1
          
        
        K
        (
        θ
        ,
        
          x
          
            ∗
          
        
        ,
        x
        
          )
          
            T
          
        
      
    
    {\displaystyle B=K(\theta ,x^{*},x^{*})-K(\theta ,x^{*},x)K(\theta ,x,x')^{-1}K(\theta ,x^{*},x)^{T}}
  где 
  
    
      
        K
        (
        θ
        ,
        
          x
          
            ∗
          
        
        ,
        x
        )
      
    
    {\displaystyle K(\theta ,x^{*},x)}
   - ковариация между новой оценкой координаты 
  
    
      
        
          x
          
            ∗
          
        
      
    
    {\displaystyle x^{*}}
   и всеми другими наблюдаемыми координатами 
  
    
      
        x
      
    
    {\displaystyle x}
   для данного гиперпараметрического вектора 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  , 
  
    
      
        K
        (
        θ
        ,
        x
        ,
        
          x
          ′
        
        )
      
    
    {\displaystyle K(\theta ,x,x')}
   и 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
   определены как и прежде, а 
  
    
      
        K
        (
        θ
        ,
        
          x
          
            ∗
          
        
        ,
        
          x
          
            ∗
          
        
        )
      
    
    {\displaystyle K(\theta ,x^{*},x^{*})}
   является дисперсией в точке 
  
    
      
        
          x
          
            ∗
          
        
      
    
    {\displaystyle x^{*}}
  , продиктованной вектором 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  . Важно отметить, что последующая средняя оценка 
  
    
      
        f
        (
        
          x
          
            ∗
          
        
        )
      
    
    {\displaystyle f(x^{*})}
   ("точечная оценка") является линейной комбинацией наблюдений 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  ; аналогичным образом дисперсия 
  
    
      
        f
        (
        
          x
          
            ∗
          
        
        )
      
    
    {\displaystyle f(x^{*})}
   фактически не зависит от наблюдений 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  . Известным узким местом в прогнозировании гауссовского процесса является то, что вычислительная сложность прогнозирования является кубической по числу точек 
  
    
      
        
          |
        
        x
        
          |
        
      
    
    {\displaystyle |x|}
  , то есть вычисление может быть невозможным для больших наборов данных. Чтобы обойти эту проблему, ведутся работы по разреженным гауссовским процессам, которые обычно основаны на идее построения репрезентативного набора для данного процесса 
  
    
      
        f
      
    
    {\displaystyle f}
  .

См. также
Среднеквадратическое отклонение
Кригинг
Априорная вероятность

Примечания
Внешние ссылки
The Gaussian Processes Web Site, including the text of Rasmussen and Williams' Gaussian Processes for Machine Learning
A gentle introduction to Gaussian processes
A Review of Gaussian Random Fields and Correlation Functions

Программное обеспечение
STK: a Small (Matlab/Octave) Toolbox for Kriging and GP modeling
Kriging module in UQLab framework (Matlab)
Matlab/Octave function for stationary Gaussian fields
Yelp MOE – A black box optimization engine using Gaussian process learning
ooDACE – A flexible object-oriented Kriging matlab toolbox.
GPstuff – Gaussian process toolbox for Matlab and Octave
GPy – A Gaussian processes framework in Python
Interactive Gaussian process regression demo
Basic Gaussian process library written in C++11
scikit-learn – A machine learning library for Python which includes Gaussian process regression and classification
[1] - The Kriging toolKit (KriKit) is developed at the Institute of Bio- and Geosciences 1 (IBG-1) of Forschungszentrum Jülich (FZJ)