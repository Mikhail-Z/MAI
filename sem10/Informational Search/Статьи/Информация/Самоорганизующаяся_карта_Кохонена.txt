Самоорганизу́ющаяся ка́рта Ко́хонена  (англ. Self-organizing map — SOM) — нейронная сеть с обучением без учителя, выполняющая задачу визуализации и кластеризации. Идея сети предложена финским учёным Т. Кохоненом. Является методом проецирования многомерного пространства в пространство с более низкой размерностью (чаще всего, двумерное), применяется также для решения задач моделирования, прогнозирования, выявление наборов независимых признаков, поиска закономерностей в больших массивах данных, разработке компьютерных игр, квантизации цветов к их ограниченному числу индексов в цветовой палитре: при печати на принтере и ранее на ПК или же на приставках с дисплеем с пониженным числом цветов, для архиваторов [общего назначения] или видео-кодеков, и прч. Является одной из версий нейронных сетей Кохонена.

История
Метод был предложен финским учёным Теуво Кохоненом в 1984 году. Существует множество модификаций исходной модели.

Структура сети
Самоорганизующаяся карта состоит из компонентов, называемых узлами или нейронами. Их количество задаётся аналитиком. Каждый из узлов описывается двумя векторами. Первый — т. н. вектор веса m, имеющий такую же размерность, что и входные данные. Второй — вектор r, представляющий собой координаты узла на карте. Карта Кохонена визуально отображается с помощью ячеек прямоугольной или шестиугольной формы; последняя применяется чаще, поскольку в этом случае расстояния между центрами смежных ячеек одинаковы, что повышает корректность визуализации карты.
Изначально известна размерность входных данных, по ней некоторым образом строится первоначальный вариант карты. В процессе обучения векторы веса узлов приближаются к входным данным. Для каждого наблюдения (семпла) выбирается наиболее похожий по вектору веса узел, и значение его вектора веса приближается к наблюдению. Также к наблюдению приближаются векторы веса нескольких узлов, расположенных рядом, таким образом если в множестве входных данных два наблюдения были схожи, на карте им будут соответствовать близкие узлы. Циклический процесс обучения, перебирающий входные данные, заканчивается по достижении картой допустимой (заранее заданной аналитиком) погрешности, или по совершении заданного количества итераций. Таким образом, в результате обучения карта Кохонена классифицирует входные данные на кластеры и визуально отображает многомерные входные данные в двумерной плоскости, распределяя векторы близких признаков в соседние ячейки и раскрашивая их в зависимости от анализируемых параметров нейронов.
В результате работы алгоритма получаются следующие карты:

карта входов нейронов — визуализирует внутреннюю структуру входных данных путём подстройки весов нейронов карты. Обычно используется несколько карт входов, каждая из которых отображает один из них и раскрашивается в зависимости от веса нейрона. На одной из карт определенным цветом обозначают область, в которую включаются приблизительно одинаковые входы для анализируемых примеров.
карта выходов нейронов — визуализирует модель взаимного расположения входных примеров. Очерченные области на карте представляют собой кластеры, состоящие из нейронов со схожими значениями выходов.
специальные карты — это карта кластеров, полученных в результате применения алгоритма самоорганизующейся карты Кохонена, а также другие карты, которые их характеризуют.

Работа сети
Инициализация карты, то есть первоначальное задание векторов веса для узлов.
Цикл:
Выбор следующего наблюдения (вектора из множества входных данных).
Нахождение для него лучшей единицы соответствия (best matching unit, BMU, или Winner) — узла на карте, вектор веса которого меньше всего отличается от наблюдения (в метрике, задаваемой аналитиком, чаще всего, евклидовой).
Определение количества соседей BMU и обучение — изменение векторов веса BMU и его соседей с целью их приближения к наблюдению.
Определение ошибки карты.

Алгоритм
ИнициализацияНаиболее распространены три способа задания первоначальных весов узлов:

Задание всех координат случайными числами.
Присваивание вектору веса значение случайного наблюдения из входных данных.
Выбор векторов веса из линейного пространства, натянутого на главные компоненты набора входных данных.
ЦиклПусть 
  
    
      
        t
      
    
    {\displaystyle t}
   — номер итерации (инициализация соответствует номеру 0).

Выбрать произвольное наблюдение 
  
    
      
        x
        (
        t
        )
      
    
    {\displaystyle x(t)}
   из множества входных данных.
Найти расстояния от него до векторов веса всех узлов карты и определить ближайший по весу узел 
  
    
      
        
          M
          
            c
          
        
        (
        t
        )
      
    
    {\displaystyle M_{c}(t)}
  . Это — BMU или Winner. Условие на 
  
    
      
        
          M
          
            c
          
        
        (
        t
        )
      
    
    {\displaystyle M_{c}(t)}
  :
  
    
      
        ‖
        x
        (
        t
        )
        −
        
          m
          
            c
          
        
        (
        t
        )
        ‖
        ≤
        ‖
        x
        (
        t
        )
        −
        
          m
          
            i
          
        
        (
        t
        )
        ‖
      
    
    {\displaystyle \|x(t)-m_{c}(t)\|\leq \|x(t)-m_{i}(t)\|}
  ,
для любого 
  
    
      
        
          m
          
            i
          
        
        (
        t
        )
      
    
    {\displaystyle m_{i}(t)}
  , где 
  
    
      
        
          m
          
            i
          
        
        (
        t
        )
      
    
    {\displaystyle m_{i}(t)}
   — вектор веса узла 
  
    
      
        
          M
          
            i
          
        
        (
        t
        )
      
    
    {\displaystyle M_{i}(t)}
  . Если находится несколько узлов, удовлетворяющих условию, BMU выбирается случайным образом среди них.Определить с помощью функции 
  
    
      
        h
      
    
    {\displaystyle h}
   (функции соседства) соседей 
  
    
      
        
          M
          
            c
          
        
      
    
    {\displaystyle M_{c}}
   и изменение их векторов веса.
Задание 
  
    
      
        h
      
    
    {\displaystyle h}
  Функция определяет «меру соседства» узлов 
  
    
      
        
          M
          
            i
          
        
      
    
    {\displaystyle M_{i}}
   и 
  
    
      
        
          M
          
            c
          
        
      
    
    {\displaystyle M_{c}}
   и изменение векторов веса. Она должна постепенно уточнять их значения, сначала у большего количества узлов и сильнее, потом у меньшего и слабее. Часто в качестве функции соседства используется гауссовская функция:
  
    
      
        
          h
          
            c
            i
          
        
        (
        t
        )
        =
        α
        (
        t
        )
        ⋅
        exp
        ⁡
        (
        −
        
          
            
              ‖
              
                r
                
                  c
                
              
              −
              
                r
                
                  i
                
              
              
                ‖
                
                  2
                
              
            
            
              2
              
                σ
                
                  2
                
              
              (
              t
              )
            
          
        
        )
      
    
    {\displaystyle h_{ci}(t)=\alpha (t)\cdot \exp(-{\frac {\|r_{c}-r_{i}\|^{2}}{2\sigma ^{2}(t)}})}
  где 
  
    
      
        0
        <
        α
        (
        t
        )
        <
        1
      
    
    {\displaystyle 0<\alpha (t)<1}
   — обучающий сомножитель, монотонно убывающий с каждой последующей итерацией (то есть определяющий приближение значения векторов веса BMU и его соседей к наблюдению; чем больше шаг, тем меньше уточнение);

  
    
      
        
          r
          
            i
          
        
      
    
    {\displaystyle r_{i}}
  , 
  
    
      
        
          r
          
            c
          
        
      
    
    {\displaystyle r_{c}}
   — координаты узлов 
  
    
      
        
          M
          
            i
          
        
        (
        t
        )
      
    
    {\displaystyle M_{i}(t)}
   и 
  
    
      
        
          M
          
            c
          
        
        (
        t
        )
      
    
    {\displaystyle M_{c}(t)}
   на карте;

  
    
      
        σ
        (
        t
        )
      
    
    {\displaystyle \sigma (t)}
   — сомножитель, уменьшающий количество соседей с итерациями, монотонно убывает.
Параметры 
  
    
      
        α
      
    
    {\displaystyle \alpha }
  , 
  
    
      
        σ
      
    
    {\displaystyle \sigma }
   и их характер убывания задаются аналитиком.Более простой способ задания функции соседства:
  
    
      
        
          h
          
            c
            i
          
        
        (
        t
        )
        =
        α
        (
        t
        )
      
    
    {\displaystyle h_{ci}(t)=\alpha (t)}
  ,если 
  
    
      
        
          M
          
            i
          
        
        (
        t
        )
      
    
    {\displaystyle M_{i}(t)}
   находится в окрестности 
  
    
      
        
          M
          
            c
          
        
        (
        t
        )
      
    
    {\displaystyle M_{c}(t)}
   заранее заданного аналитиком радиуса, и 0 в противном случае.Функция 
  
    
      
        h
        (
        t
        )
      
    
    {\displaystyle h(t)}
   равна 
  
    
      
        α
        (
        t
        )
      
    
    {\displaystyle \alpha (t)}
   для BMU и уменьшается с удалением от BMU.Изменение векторов весаИзменить вектор веса по формуле:
  
    
      
        
          m
          
            i
          
        
        (
        t
        )
        =
        
          m
          
            i
          
        
        (
        t
        −
        1
        )
        +
        
          h
          
            c
            i
          
        
        (
        t
        )
        ⋅
        (
        x
        (
        t
        )
        −
        
          m
          
            i
          
        
        (
        t
        −
        1
        )
        )
      
    
    {\displaystyle m_{i}(t)=m_{i}(t-1)+h_{ci}(t)\cdot (x(t)-m_{i}(t-1))}
  Т.о. вектора веса всех узлов, являющихся соседями BMU, приближаются к рассматриваемому наблюдению.Вычисление ошибки картыНапример, как среднее арифметическое расстояний между наблюдениями и векторами веса соответствующих им BMU:
  
    
      
        
          
            1
            N
          
        
        
          ∑
          
            i
            =
            1
          
          
            N
          
        
        ‖
        
          x
          
            i
          
        
        −
        
          m
          
            c
          
        
        ‖
      
    
    {\displaystyle {\frac {1}{N}}\sum _{i=1}^{N}\|x_{i}-m_{c}\|}
  ,где N — количество элементов набора входных данных.

Особенности модели
Устойчивость к зашумленным данным, быстрое и неуправляемое обучение, возможность упрощения многомерных входных данных с помощью визуализации.Самоорганизующиеся карты Кохонена могут быть использованы для кластерного анализа только в том случае, если заранее известно число кластеров.
Важным недостатком является то, что окончательный результат работы нейронных сетей зависит от начальных установок сети. С другой стороны, нейронные сети теоретически могут аппроксимировать любую непрерывную функцию, что позволяет исследователю не принимать заранее какие-либо гипотезы относительно модели.

См. также
Нейронная сеть Кохонена
Упругая карта
WEBSOM

Примечания
Литература
T. Kohonen, Self-Organizing Maps (Third Extended Edition), New York, 2001, 501 pages. ISBN 3-540-67921-9
Дебок Г., Кохонен Т. Анализ финансовых данных с помощью самоорганизующихся карт, Альпина Паблишер, 2001, 317 стр. ISBN 5-89684-013-6
Зиновьев А. Ю. Визуализация многомерных данных. — Красноярск: Изд. Красноярского государственного технического университета, 2000. — 180 с.
Чубукова И.А. Data Mining. — 2000. — 326 с.
Манжула В.Г., Федяшов Д.С. Нейронные сети Кохонена и нечеткие нейронные сети в интеллектуальном анализе данных. — 2011.
Lakhmi C. Jain; N.M. Martin Fusion of Neural Networks, Fuzzy Systems and Genetic Algorithms: Industrial Applications. — CRC Press, CRC Press LLC, 1998

Ссылки
SOM-Research на сайте Хельсинкского технического университета
WEBSOM, a Kohonen network project
PCA, SOM and GSOM: applet, Е. М. Миркес и университет Лейстера. Метод главных компонент, самоорганизующиеся карты и растущие самоорганизующиеся карты. Глава онлайн учебника c программами, позволяющими проводить сравнительные исследования.
Лекция по самоорганизующимся картам Кохонена