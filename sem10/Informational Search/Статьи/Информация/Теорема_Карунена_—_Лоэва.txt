Важным принципиальным вопросом теории дискретизации является вопрос об объёме дискретного описания сигналов, то есть о количестве 
  
    
      
        N
      
    
    {\displaystyle N}
   базисных функций, используемых для представления:

  
    
      
        a
        (
        t
        )
        =
        
          ∑
          
            k
            =
            0
          
          
            N
            −
            1
          
        
        
          α
          
            k
          
        
        
          φ
          
            k
          
        
        (
        t
        )
      
    
    {\displaystyle a(t)=\sum _{k=0}^{N-1}\alpha _{k}\varphi _{k}(t)}
  .Чтобы найти оптимальный базис, нужно определить класс сигналов, для которого он отыскивается, а также задать точность восстановления для этого класса. При статистическом подходе к описанию сигналов оптимальным 
  
    
      
        N
      
    
    {\displaystyle N}
   — мерным базисом для представления отдельных реализаций сигналов обычно считается базис, при котором норма ошибки, усредненная по ансамблю реализаций, минимальна. В этом случае необходимые и достаточные условия минимума нормы ошибки представления сигнала в виде суммы базисных функций определяет теорема Карунена-Лоэва.

Популярная формулировка
Минимальное значение нормы ошибки представления сигналов на интервале протяженностью 
  
    
      
        T
      
    
    {\displaystyle T}
   достигается при использовании в качестве базиса собственных функций оператора, ядром которого является корреляционная функция сигналов 
  
    
      
        
          R
          
            a
          
        
        (
        t
        ,
        τ
        )
      
    
    {\displaystyle R_{a}(t,\tau )}
  :

  
    
      
        
          ∫
          
            −
            
              
                T
                2
              
            
          
          
            
              T
              2
            
          
        
        
          R
          
            a
          
        
        (
        t
        ,
        τ
        )
        
          φ
          
            k
          
        
        (
        τ
        )
        d
        τ
        =
        
          λ
          
            k
          
        
        
          φ
          
            k
          
        
        (
        t
        )
      
    
    {\displaystyle \int _{-{\frac {T}{2}}}^{\frac {T}{2}}R_{a}(t,\tau )\varphi _{k}(\tau )d\tau =\lambda _{k}\varphi _{k}(t)}
  ,соответствующих 
  
    
      
        N
      
    
    {\displaystyle N}
   наибольшим собственным значениям.
При этом норма ошибки равна:

  
    
      
        ‖
        ϵ
        
          ‖
          
            m
            i
            n
          
          
            2
          
        
        =
        ‖
        a
        (
        t
        )
        −
        
          ∑
          
            k
            =
            0
          
          
            N
            −
            1
          
        
        
          α
          
            k
          
        
        
          φ
          
            k
          
        
        (
        t
        )
        
          ‖
          
            m
            i
            n
          
          
            2
          
        
        =
        
          ∑
          
            k
            =
            N
          
          
            ∞
          
        
        
          λ
          
            k
          
        
      
    
    {\displaystyle \|\epsilon \|_{min}^{2}=\|a(t)-\sum _{k=0}^{N-1}\alpha _{k}\varphi _{k}(t)\|_{min}^{2}=\sum _{k=N}^{\infty }\lambda _{k}}
  .Такое разложение является разложением Карунена-Лоэва.

Применение
В теории случайных процессов теорема Карунена-Лоэва  (названа в честь Кари Карунена и Мишеля Лоэва) — представление случайного процесса в виде бесконечной линейной комбинации ортогональных функций, аналогичное представлению рядов Фурье — последовательному представлению функций на ограниченном интервале. В отличие от рядов Фурье, где коэффициенты являются действительными числами и базис представления состоит из синусоидальных функций (то есть, из функций синус и косинус с разными частотами), коэффициенты в теореме Карунена-Лоэва — случайные переменные, и базис представления зависит от процесса. Ортогональные базисные функции, использованные в этом представлении, определяет функция ковариации процесса. Если мы рассматриваем стохастический процесс как случайную функцию F, то есть процесс, в котором функция на интервале [a, b] принимает значение F, то эта теорема может рассматриваться как случайное ортонормальное разложение F.
Центрированный случайный процесс {Xt}t ∈ [a, b] (где центрирование означает, что математические ожидания E(Xt) существуют и равны нулю для всех значений параметра t из [a, b]), удовлетворяющий техническому условию непрерывности, допускает разложение следующего вида:

  
    
      
        
          
            X
          
          
            t
          
        
        =
        
          ∑
          
            k
            =
            1
          
          
            ∞
          
        
        
          
            Z
          
          
            k
          
        
        
          e
          
            k
          
        
        (
        t
        )
        .
      
    
    {\displaystyle \mathbf {X} _{t}=\sum _{k=1}^{\infty }\mathbf {Z} _{k}e_{k}(t).}
  где Zk — взаимнонекоррелированые случайные величины и функции ek — непрерывные вещественные функции на [a, b], ортогональные в L² [a, b]. В случае нецентрированного процесса имеет место аналогичное разложение, получаемое разложением функции математического ожидания в базисе ek.
Если процесс 
  
    
      
        
          
            X
          
          
            t
          
        
      
    
    {\displaystyle \mathbf {X} _{t}}
   гауссовский, то случайные величины Zk — тоже гауссовские и являются независимыми. Этот результат обобщает преобразования Карунена-Лоэва. Важным примером центрированного случайного процесса на интервале [0,1] является винеровский процесс, и теорема Карунена-Лоэва может быть использована для получения канонического ортогонального представления. В этом случае разложение состоит из синусоидальных функций.
Приведенные выше разложения в также известны как разложения или декомпозиция Карунена-Лоэва (эмпирическая версия, то есть, с коэффициентами из исходных числовых данных), как анализ главных компонент, собственное ортогональное разложение или преобразование Хотеллинга.

Формулировка
Сформулируем результат в терминах комплекснозначных стохастических процессов. Результаты могут быть применены к вещественнозначным процессам без модификаций, вспоминая, что число, комплексно-сопряженное с действительным числом, совпадает с ним самим.
Для случайных элементов X и Y скалярное произведение определяется формулой

  
    
      
        ⟨
        
          X
        
        
          |
        
        
          Y
        
        ⟩
        =
        E
        ⁡
        (
        
          
            X
            
              ∗
            
          
        
        
          Y
        
        )
      
    
    {\displaystyle \langle \mathbf {X} |\mathbf {Y} \rangle =\operatorname {E} (\mathbf {X^{*}} \mathbf {Y} )}
  где * обозначает операцию комплексного сопряжения.

Статистики второго порядка
Скалярное произведение корректно определено, если как 
  
    
      
        X
      
    
    {\displaystyle X}
  , так и 
  
    
      
        Y
      
    
    {\displaystyle Y}
   имеют конечные вторые моменты, или, что то же самое, если они оба квадратично интегрируемы. Отметим, что скалярное произведение связано с ковариацией и корреляцией. В частности, для случайных переменных со средним нулевым значением, ковариация и скалярное произведение совпадают. Функция автоковариации 
  
    
      
        
          K
          
            
              X
              X
            
          
        
      
    
    {\displaystyle K_{\mathrm {XX} }}
  

  
    
      
        
          K
          
            
              X
              X
            
          
        
        (
        t
        ,
        s
        )
        =
        Cov
        ⁡
        [
        X
        (
        t
        )
        ,
        X
        (
        s
        )
        ]
        =
        ⟨
        
          
            X
          
          
            t
          
        
        
          |
        
        
          
            X
          
          
            s
          
        
        ⟩
      
    
    {\displaystyle K_{\mathrm {XX} }(t,s)=\operatorname {Cov} [X(t),X(s)]=\langle \mathbf {X} _{t}|\mathbf {X} _{s}\rangle }
  
  
    
      
        =
        
          E
        
        {
        [
        X
        (
        t
        )
        −
        
          μ
          
            X
          
        
        (
        t
        )
        
          ]
          
            ∗
          
        
        [
        X
        (
        s
        )
        −
        
          μ
          
            X
          
        
        (
        s
        )
        ]
        }
      
    
    {\displaystyle =\mathrm {E} \{[X(t)-\mu _{X}(t)]^{*}[X(s)-\mu _{X}(s)]\}}
  
  
    
      
        =
        
          E
        
        {
        
          X
          
            ∗
          
        
        (
        t
        )
        X
        (
        s
        )
        }
        −
        
          μ
          
            X
          
          
            ∗
          
        
        (
        t
        )
        
          μ
          
            X
          
        
        (
        s
        )
      
    
    {\displaystyle =\mathrm {E} \{X^{*}(t)X(s)\}-\mu _{X}^{*}(t)\mu _{X}(s)}
  
  
    
      
        =
        
          R
          
            
              X
              X
            
          
        
        (
        t
        ,
        s
        )
        −
        
          μ
          
            X
          
          
            ∗
          
        
        (
        t
        )
        
          μ
          
            X
          
        
        (
        s
        )
        .
      
    
    {\displaystyle =R_{\mathrm {XX} }(t,s)-\mu _{X}^{*}(t)\mu _{X}(s).}
  Если процесс {Xt}t центрированный, то

  
    
      
        
          μ
          
            X
          
        
        (
        t
        )
        =
        0
      
    
    {\displaystyle \mu _{X}(t)=0}
  для всех t. Таким образом, автоковариация KXX равна автокорреляции RXX:

  
    
      
        
          K
          
            
              X
              X
            
          
        
        (
        t
        ,
        s
        )
        =
        
          R
          
            
              X
              X
            
          
        
        (
        t
        ,
        s
        )
        .
      
    
    {\displaystyle K_{\mathrm {XX} }(t,s)=R_{\mathrm {XX} }(t,s).}
  Отметим, что если {Xt}t центрированный и t1, ≤ t2, …, ≤ tN являются точками на интервале [a, b], следовательно

  
    
      
        
          ∑
          
            k
            ,
            ℓ
          
        
        
          Cov
          
            
              X
            
          
        
        ⁡
        (
        
          t
          
            k
          
        
        ,
        
          t
          
            ℓ
          
        
        )
        =
        Var
        ⁡
        
          (
          
            
              ∑
              
                k
                =
                1
              
              
                N
              
            
            
              
                X
              
              
                k
              
            
          
          )
        
        ≥
        0.
      
    
    {\displaystyle \sum _{k,\ell }\operatorname {Cov} _{\mathbf {X} }(t_{k},t_{\ell })=\operatorname {Var} \left(\sum _{k=1}^{N}\mathbf {X} _{k}\right)\geq 0.}

Формулировка теоремы
Теорема. Рассмотрим центрированный случайный процесс 
  
    
      
        {
        
          
            X
          
          
            t
          
        
        }
      
    
    {\displaystyle \{\mathbf {X} _{t}\}}
  , индексированный 
  
    
      
        t
      
    
    {\displaystyle t}
   на интервале 
  
    
      
        [
        a
        ,
        b
        ]
      
    
    {\displaystyle [a,b]}
   с ковариационной функцией 
  
    
      
        
          
            C
            o
            v
          
          
            
              X
            
          
        
      
    
    {\displaystyle \mathrm {Cov} _{\mathbf {X} }}
  . Предположим, что ковариационная функция 
  
    
      
        
          
            C
            o
            v
          
          
            
              X
            
          
        
        (
        t
        ,
        s
        )
      
    
    {\displaystyle \mathrm {Cov} _{\mathbf {X} }(t,s)}
   непрерывна по совокупности переменных 
  
    
      
        t
        ,
        s
      
    
    {\displaystyle t,s}
  . Тогда 
  
    
      
        
          
            C
            o
            v
          
          
            
              X
            
          
        
      
    
    {\displaystyle \mathrm {Cov} _{\mathbf {X} }}
   — положительно определенное ядро, и по теореме Мерсера интегральный оператор 
  
    
      
        T
      
    
    {\displaystyle T}
   в 
  
    
      
        
          L
          
            2
          
        
        [
        a
        ,
        b
        ]
      
    
    {\displaystyle L^{2}[a,b]}
   (близкой к мере Лебега на 
  
    
      
        [
        a
        ,
        b
        ]
      
    
    {\displaystyle [a,b]}
  ) имеет ортонормированный базис из собственных векторов. Пусть 
  
    
      
        {
        
          e
          
            i
          
        
        }
      
    
    {\displaystyle \{e_{i}\}}
   являются собственными векторами 
  
    
      
        T
      
    
    {\displaystyle T}
  , соответствующими ненулевым собственным значениям и

  
    
      
        
          
            Z
          
          
            i
          
        
        =
        
          ∫
          
            a
          
          
            b
          
        
        
          
            X
          
          
            t
          
        
        
          e
          
            i
          
        
        (
        t
        )
        d
        t
        .
      
    
    {\displaystyle \mathbf {Z} _{i}=\int _{a}^{b}\mathbf {X} _{t}e_{i}(t)dt.}
  Тогда 
  
    
      
        
          Z
          
            i
          
        
      
    
    {\displaystyle Z_{i}}
   — центрированные ортогональные случайные величины и

  
    
      
        
          
            X
          
          
            t
          
        
        =
        
          ∑
          
            i
            =
            1
          
          
            ∞
          
        
        
          e
          
            i
          
        
        (
        t
        )
        
          
            Z
          
          
            i
          
        
      
    
    {\displaystyle \mathbf {X} _{t}=\sum _{i=1}^{\infty }e_{i}(t)\mathbf {Z} _{i}}
  ряд сходится в среднем квадратичном, а также равномерно по 
  
    
      
        t
      
    
    {\displaystyle t}
  . Кроме того

  
    
      
        Var
        ⁡
        (
        
          
            Z
          
          
            i
          
        
        )
        =
        E
        ⁡
        (
        
          
            Z
          
          
            i
          
          
            2
          
        
        )
        =
        
          λ
          
            i
          
        
        .
      
    
    {\displaystyle \operatorname {Var} (\mathbf {Z} _{i})=\operatorname {E} (\mathbf {Z} _{i}^{2})=\lambda _{i}.}
  где 
  
    
      
        
          λ
          
            i
          
        
      
    
    {\displaystyle \lambda _{i}}
   собственное значение, соответствующее собственному вектору 
  
    
      
        
          e
          
            i
          
        
      
    
    {\displaystyle e_{i}}
  .

Суммы Коши
В формулировке теоремы интеграл в определении 
  
    
      
        
          Z
          
            i
          
        
      
    
    {\displaystyle Z_{i}}
   можно понимать как предел в среднем сумм Коши случайных величин

  
    
      
        
          ∑
          
            k
            =
            0
          
          
            ℓ
            −
            1
          
        
        
          
            X
          
          
            
              ξ
              
                k
              
            
          
        
        
          e
          
            i
          
        
        (
        
          ξ
          
            k
          
        
        )
        (
        
          t
          
            k
            +
            1
          
        
        −
        
          t
          
            k
          
        
        )
        ,
      
    
    {\displaystyle \sum _{k=0}^{\ell -1}\mathbf {X} _{\xi _{k}}e_{i}(\xi _{k})(t_{k+1}-t_{k}),}
  где

  
    
      
        a
        =
        
          t
          
            0
          
        
        ≤
        
          ξ
          
            0
          
        
        ≤
        
          t
          
            1
          
        
        ≤
        ⋯
        ≤
        
          ξ
          
            ℓ
            −
            1
          
        
        ≤
        
          t
          
            n
          
        
        =
        b
      
    
    {\displaystyle a=t_{0}\leq \xi _{0}\leq t_{1}\leq \cdots \leq \xi _{\ell -1}\leq t_{n}=b}

Особый случай: гауссовское распределение
Так как предел в среднем квадратичном из совместно гауссовских случайных величин является гауссовским и совместно гауссовские случайные (центрированные) величины независимы тогда и только тогда, когда они являются ортогональными, мы можем также заключить:
Теорема. Случайные величины 
  
    
      
        
          Z
          
            i
          
        
      
    
    {\displaystyle Z_{i}}
   имеют гауссовское распределение и являются независимыми, если первоначальный процесс {Xt}t тоже является гауссовским.
В гауссовском случае, поскольку случайные величины 
  
    
      
        
          Z
          
            i
          
        
      
    
    {\displaystyle Z_{i}}
   являются независимыми, мы можем быть уверены в том, что:

  
    
      
        
          lim
          
            N
            →
            ∞
          
        
        
          ∑
          
            i
            =
            1
          
          
            N
          
        
        
          e
          
            i
          
        
        (
        t
        )
        
          
            Z
          
          
            i
          
        
        (
        ω
        )
        =
        
          
            X
          
          
            t
          
        
        (
        ω
        )
      
    
    {\displaystyle \lim _{N\rightarrow \infty }\sum _{i=1}^{N}e_{i}(t)\mathbf {Z} _{i}(\omega )=\mathbf {X} _{t}(\omega )}
  почти наверное.
Отметим, что обобщая теорему Мерсера, мы можем заменить интервал 
  
    
      
        [
        a
        ,
        b
        ]
      
    
    {\displaystyle [a,b]}
   другими компактными пространствами 
  
    
      
        C
      
    
    {\displaystyle C}
   , а меру Лебега на 
  
    
      
        [
        a
        ,
        b
        ]
      
    
    {\displaystyle [a,b]}
   — борелевской мерой с носителем в 
  
    
      
        C
      
    
    {\displaystyle C}
  .

Винеровский процесс
Винеровский процесс в теории случайных процессов — это математическая модель броуновского движения или случайного блуждания с непрерывным временем. Здесь мы определяем его как центрированный гауссовский процесс B(t) с ковариационной функцией

  
    
      
        
          
            K
          
          
            
              B
              B
            
          
        
        (
        t
        ,
        s
        )
        =
        Cov
        ⁡
        (
        B
        (
        t
        )
        ,
        B
        (
        s
        )
        )
        =
        min
        (
        s
        ,
        t
        )
        .
      
    
    {\displaystyle \mathrm {K} _{\mathrm {BB} }(t,s)=\operatorname {Cov} (B(t),B(s))=\min(s,t).}
  Легко видеть, что собственные векторы ковариации равны

  
    
      
        
          e
          
            k
          
        
        (
        t
        )
        =
        
          
            2
          
        
        sin
        ⁡
        
          (
          
            k
            −
            
              
                1
                2
              
            
          
          )
        
        π
        t
      
    
    {\displaystyle e_{k}(t)={\sqrt {2}}\sin \left(k-{\frac {1}{2}}\right)\pi t}
  а соответствующие собственные значения

  
    
      
        
          λ
          
            k
          
        
        =
        
          
            4
            
              (
              2
              k
              −
              1
              
                )
                
                  2
                
              
              
                π
                
                  2
                
              
            
          
        
        .
      
    
    {\displaystyle \lambda _{k}={\frac {4}{(2k-1)^{2}\pi ^{2}}}.}
  Это позволяет получить нам следующее представление винеровского процесса:
Теорема. Существует последовательность {Wi}i независимых гауссовких случайных величин с нулевым средним и единичной дисперсией такая, что

  
    
      
        
          
            B
          
          
            t
          
        
        =
        
          
            2
          
        
        
          ∑
          
            k
            =
            1
          
          
            ∞
          
        
        
          
            W
          
          
            k
          
        
        
          
            
              sin
              ⁡
              
                (
                
                  k
                  −
                  
                    
                      1
                      2
                    
                  
                
                )
              
              π
              t
            
            
              
                (
                
                  k
                  −
                  
                    
                      1
                      2
                    
                  
                
                )
              
              π
            
          
        
        .
      
    
    {\displaystyle \mathbf {B} _{t}={\sqrt {2}}\sum _{k=1}^{\infty }\mathbf {W} _{k}{\frac {\sin \left(k-{\frac {1}{2}}\right)\pi t}{\left(k-{\frac {1}{2}}\right)\pi }}.}
  Сходимость является равномерной по t в норме L² так, что

  
    
      
        E
        ⁡
        
          
            (
            
              
                
                  B
                
                
                  t
                
              
              −
              
                
                  2
                
              
              
                ∑
                
                  k
                  =
                  1
                
                
                  n
                
              
              
                
                  W
                
                
                  k
                
              
              
                
                  
                    sin
                    ⁡
                    
                      (
                      
                        k
                        −
                        
                          
                            1
                            2
                          
                        
                      
                      )
                    
                    π
                    t
                  
                  
                    
                      (
                      
                        k
                        −
                        
                          
                            1
                            2
                          
                        
                      
                      )
                    
                    π
                  
                
              
            
            )
          
          
            2
          
        
        →
        0
      
    
    {\displaystyle \operatorname {E} \left(\mathbf {B} _{t}-{\sqrt {2}}\sum _{k=1}^{n}\mathbf {W} _{k}{\frac {\sin \left(k-{\frac {1}{2}}\right)\pi t}{\left(k-{\frac {1}{2}}\right)\pi }}\right)^{2}\rightarrow 0}
  равномерно по t.

Использование
Было высказано мнение, что в проекте SETI следует использовать преобразования Карунена-Лоэва для обнаружения сигналов с очень широким спектром. Аналогично, в системах адаптивной оптики иногда используют функции Карунена-Лоэва для восстановления информации о фазе фронта волны. (Dai 1996, JOSA A).

См. также
Метод главных компонент
Нейронная сеть Кохонена
Полиномиальный хаос

Ссылки
И. И. Гихман, А. В. Скороход, Введение в теорию случайных процессов.- М.: Наука, 1965.
B. Simon, Functional Integration and Quantum Physics, Academic Press, 1979
K. Karhunen, Kari, Uber lineare Methoden in der Wahrscheinlichkeitsrechnung, Ann. Acad. Sci. Fennicae. Ser. A. I. Math.-Phys., 1947, No. 37, 1-79
М. Лоев, Теория вероятностей, — М.: ИЛ, 1962.
G. Dai, Modal wave-front reconstruction with Zernike polynomials and Karhunen-Loeve functions, JOSA A, 13, 6, 1996

Примечания
Литература
Ярославский Л. П. Введение в цифровую обработку изображений. — М.: Советское радио, 1979. — 312 с.
Френкс Л. Теория сигналов. — М.: Советское радио, 1974. — 399 с.