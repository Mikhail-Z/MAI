Многомерная случайная величина или случайный вектор (математика, вероятность и статистика)  - это список математических переменных, значения каждого из которых неизвестно, либо потому что значение еще не произошло, или из-за несовершенного знания его значении. Индивидуальные переменные в случайном векторе сгруппированы вместе, потому что они являются частью единой математической системы — часто они представляют различные свойства отдельных статистических единиц. Например, пусть какое-то конкретное лицо имеет определенный возраст, рост и вес. Совокупность же этих особенностей у случайного человека из группы будет случайным вектором. Обычно каждый элемент случайного вектора - это действительное число.
Случайные вектора часто используют в качестве базовой реализации различных видов совокупности случайных величин, например, случайные матрицы, случайное дерево, случайная последовательность, случайных процессов т. д.
Более формально, многомерной случайной величиной является столбец вектора 
  
    
      
        
          X
        
        =
        (
        
          X
          
            1
          
        
        ,
        .
        .
        .
        ,
        
          X
          
            n
          
        
        
          )
          
            T
          
        
      
    
    {\displaystyle \mathbf {X} =(X_{1},...,X_{n})^{T}}
   (или ее транспонированная матрица, которая представляет собой вектор-строку), компонентами которого являются скалярные значения случайных величин одном и том же вероятностном пространстве 
  
    
      
        (
        Ω
        ,
        
          
            F
          
        
        ,
        P
        )
      
    
    {\displaystyle (\Omega ,{\mathcal {F}},P)}
  , где 
  
    
      
        Ω
      
    
    {\displaystyle \Omega }
   это пространство элементарных событий, 
  
    
      
        
          
            F
          
        
      
    
    {\displaystyle {\mathcal {F}}}
   это сигма-алгебра (совокупность всех событий), и 
  
    
      
        P
      
    
    {\displaystyle P}
   есть вероятность измерения (функция, возвращающая вероятность каждого события ).

Распределение вероятностей
Каждый случайный вектор порождает вероятностную меру на 
  
    
      
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle \mathbb {R} ^{n}}
   с борелевской алгеброй, лежащей в основе сигма-алгебры. Эта мера также известна как совместное распределение вероятностей, совместное распределение или многомерное распределение случайного вектора.
Распределение каждой из компонент случайных величин 
  
    
      
        
          X
          
            i
          
        
      
    
    {\displaystyle X_{i}}
   называются маргинальными распределениями. Условное распределение вероятностей  
  
    
      
        
          X
          
            i
          
        
      
    
    {\displaystyle X_{i}}
   учитывая 
  
    
      
        
          X
          
            j
          
        
      
    
    {\displaystyle X_{j}}
   является вероятностный распределением 
  
    
      
        
          X
          
            i
          
        
      
    
    {\displaystyle X_{i}}
   когда 
  
    
      
        
          X
          
            j
          
        
      
    
    {\displaystyle X_{j}}
   известно как конкретное значение.

Операции на случайных векторах
Случайные вектора могут быть подвергнуты тем же алгебраическим операциям как и в случае с неслучайными векторами: сложение, вычитание, умножение на скаляр, и скалярное произведение.
Аналогично, новый случайный вектор 
  
    
      
        
          Y
        
      
    
    {\displaystyle \mathbf {Y} }
   можно определить, применяя аффинное преобразование 
  
    
      
        g
        :
        
          
            R
          
          
            n
          
        
        →
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle g\colon \mathbb {R} ^{n}\to \mathbb {R} ^{n}}
   для случайного вектора 
  
    
      
        
          X
        
      
    
    {\displaystyle \mathbf {X} }
  :

  
    
      
        
          Y
        
        =
        
          
            A
          
        
        
          X
        
        +
        b
      
    
    {\displaystyle \mathbf {Y} ={\mathcal {A}}\mathbf {X} +b}
  , где 
  
    
      
        
          
            A
          
        
      
    
    {\displaystyle {\mathcal {A}}}
   это матрица 
  
    
      
        n
        ×
        n
      
    
    {\displaystyle n\times n}
    и 
  
    
      
        b
      
    
    {\displaystyle b}
   это вектор состоящий из колонки 
  
    
      
        n
        ×
        1
      
    
    {\displaystyle n\times 1}
  Если 
  
    
      
        
          
            A
          
        
      
    
    {\displaystyle {\mathcal {A}}}
   обратима и вероятностная плотность  
  
    
      
        
          
            X
          
        
      
    
    {\displaystyle \textstyle \mathbf {X} }
   равна 
  
    
      
        
          f
          
            
              X
            
          
        
      
    
    {\displaystyle f_{\mathbf {X} }}
  ,тогда вероятностная плотность  
  
    
      
        
          Y
        
      
    
    {\displaystyle \mathbf {Y} }
  

  
    
      
        
          f
          
            
              Y
            
          
        
        (
        y
        )
        =
        
          
            
              
                f
                
                  
                    X
                  
                
              
              (
              
                
                  
                    A
                  
                
                
                  −
                  1
                
              
              (
              y
              −
              b
              )
              )
            
            
              
                |
              
              det
              
                
                  A
                
              
              
                |
              
            
          
        
      
    
    {\displaystyle f_{\mathbf {Y} }(y)={\frac {f_{\mathbf {X} }({\mathcal {A}}^{-1}(y-b))}{|\det {\mathcal {A}}|}}}
  .

Математическое ожидание, ковариация и кросс-ковариация
Математическое ожидание или среднее значение случайного вектора 
  
    
      
        
          X
        
      
    
    {\displaystyle \mathbf {X} }
    фиксированный вектор 
  
    
      
        E
        ⁡
        [
        
          X
        
        ]
      
    
    {\displaystyle \operatorname {E} [\mathbf {X} ]}
  , элементы которого являются ожидаемыми значениями соответствующих случайных величин.
Ковариационная матрица (Также называется дисперсионно-ковариационной матрицей) это случайный вектор 
  
    
      
        n
        ×
        1
      
    
    {\displaystyle n\times 1}
   матрицей которого является матрица размером 
  
    
      
        n
        ×
        n
      
    
    {\displaystyle n\times n}
   в которой (i,j)ый элемент это ковариация между  i ой и  j ой случайной величиной.  Ковариационная матрица - это математическое ожидание, элемент за элементом, матрицы размером 
  
    
      
        n
        ×
        n
      
    
    {\displaystyle n\times n}
   полученной умножением матриц 
  
    
      
        [
        
          X
        
        −
        E
        ⁡
        [
        
          X
        
        ]
        ]
        [
        
          X
        
        −
        E
        ⁡
        [
        
          X
        
        ]
        
          ]
          
            T
          
        
      
    
    {\displaystyle [\mathbf {X} -\operatorname {E} [\mathbf {X} ]][\mathbf {X} -\operatorname {E} [\mathbf {X} ]]^{T}}
  , где верхний индекс T относится к транспонированию указанного вектора:

  
    
      
        Var
        ⁡
        [
        
          X
        
        ]
        =
        E
        ⁡
        [
        (
        
          X
        
        −
        E
        ⁡
        [
        
          X
        
        ]
        )
        (
        
          X
        
        −
        E
        ⁡
        [
        
          X
        
        ]
        
          )
          
            T
          
        
        ]
        .
      
    
    {\displaystyle \operatorname {Var} [\mathbf {X} ]=\operatorname {E} [(\mathbf {X} -\operatorname {E} [\mathbf {X} ])(\mathbf {X} -\operatorname {E} [\mathbf {X} ])^{T}].}
  В дополнение к этому, 
  
    
      
        
          X
        
      
    
    {\displaystyle \mathbf {X} }
   и 
  
    
      
        
          Y
        
      
    
    {\displaystyle \mathbf {Y} }
   (
  
    
      
        
          X
        
      
    
    {\displaystyle \mathbf {X} }
   имеет 
  
    
      
        n
      
    
    {\displaystyle n}
   элементов и 
  
    
      
        
          Y
        
      
    
    {\displaystyle \mathbf {Y} }
   имеет 
  
    
      
        p
      
    
    {\displaystyle p}
   элементов ) является матрицей 
  
    
      
        n
        ×
        p
      
    
    {\displaystyle n\times p}
  

  
    
      
        Cov
        ⁡
        [
        
          X
        
        ,
        
          Y
        
        ]
        =
        E
        ⁡
        [
        (
        
          X
        
        −
        E
        ⁡
        [
        
          X
        
        ]
        )
        (
        
          Y
        
        −
        E
        ⁡
        [
        
          Y
        
        ]
        
          )
          
            T
          
        
        ]
        ,
      
    
    {\displaystyle \operatorname {Cov} [\mathbf {X} ,\mathbf {Y} ]=\operatorname {E} [(\mathbf {X} -\operatorname {E} [\mathbf {X} ])(\mathbf {Y} -\operatorname {E} [\mathbf {Y} ])^{T}],}
  Где опять указанное матричное ожидание принимается поэтапно в матрице. Here the (i,j)th element is the covariance between the i th element of 
  
    
      
        
          X
        
      
    
    {\displaystyle \mathbf {X} }
   and the j th element of 
  
    
      
        
          Y
        
        .
      
    
    {\displaystyle \mathbf {Y} .}
    The cross-covariance matrix 
  
    
      
        Cov
        ⁡
        [
        
          Y
        
        ,
        
          X
        
        ]
      
    
    {\displaystyle \operatorname {Cov} [\mathbf {Y} ,\mathbf {X} ]}
   is simply the transpose of the matrix 
  
    
      
        Cov
        ⁡
        [
        
          X
        
        ,
        
          Y
        
        ]
      
    
    {\displaystyle \operatorname {Cov} [\mathbf {X} ,\mathbf {Y} ]}
  .

Дополнительные свойства
Ожидание квадратичной формы
Возьмем математическое ожидание квадратичной формы в случайном векторе X следующим образом::стр.170–171

  
    
      
        E
        ⁡
        (
        
          X
          
            T
          
        
        A
        X
        )
        =
        [
        E
        ⁡
        (
        X
        )
        
          ]
          
            T
          
        
        A
        [
        E
        ⁡
        (
        X
        )
        ]
        +
        tr
        ⁡
        (
        A
        C
        )
        ,
      
    
    {\displaystyle \operatorname {E} (X^{T}AX)=[\operatorname {E} (X)]^{T}A[\operatorname {E} (X)]+\operatorname {tr} (AC),}
  Где C - ковариационная матрица X, а tr - это след матрицы, то есть сумма элементов на его главной диагонали (от верхнего левого к правому нижнему). Так как квадратичная форма является скаляром, то это и ее математическое ожидание.
Доказательство: Пусть 
  
    
      
        
          z
        
      
    
    {\displaystyle \mathbf {z} }
   - случайный вектор размера 
  
    
      
        m
        ×
        1
      
    
    {\displaystyle m\times 1}
   с 
  
    
      
        E
        ⁡
        [
        
          z
        
        ]
        =
        μ
      
    
    {\displaystyle \operatorname {E} [\mathbf {z} ]=\mu }
   и 
  
    
      
        Cov
        ⁡
        [
        
          z
        
        ]
        =
        V
      
    
    {\displaystyle \operatorname {Cov} [\mathbf {z} ]=V}
   и пусть 
  
    
      
        A
      
    
    {\displaystyle A}
   - нестохастическая матрица размера  
  
    
      
        m
        ×
        m
      
    
    {\displaystyle m\times m}
  
Тогда, основываясь на базовой формуле ковариации , если мы обозначим 
  
    
      
        
          
            z
          
          ′
        
        =
        
          X
        
      
    
    {\displaystyle \mathbf {z} '=\mathbf {X} }
   и 
  
    
      
        
          
            z
          
          ′
        
        
          A
          ′
        
        =
        
          Y
        
      
    
    {\displaystyle \mathbf {z} 'A'=\mathbf {Y} }
   ( где в дальнейшем основной знак  
  
    
      
        
          
          ′
        
      
    
    {\displaystyle '}
   обозначает транспонирование), мы видим:

  
    
      
        Cov
        ⁡
        [
        
          X
        
        ,
        
          Y
        
        ]
        =
        E
        ⁡
        [
        
          X
        
        
          
            Y
          
          ′
        
        ]
        −
        E
        ⁡
        [
        
          X
        
        ]
        E
        ⁡
        [
        
          Y
        
        
          ]
          ′
        
      
    
    {\displaystyle \operatorname {Cov} [\mathbf {X} ,\mathbf {Y} ]=\operatorname {E} [\mathbf {X} \mathbf {Y} ']-\operatorname {E} [\mathbf {X} ]\operatorname {E} [\mathbf {Y} ]'}
  Следовательно,

  
    
      
        
          
            
              
                E
                (
                X
                
                  Y
                  ′
                
                )
              
              
                
                =
                Cov
                ⁡
                (
                X
                ,
                Y
                )
                +
                E
                (
                X
                )
                E
                (
                Y
                
                  )
                  ′
                
              
            
            
              
                E
                (
                
                  z
                  ′
                
                A
                z
                )
              
              
                
                =
                Cov
                ⁡
                (
                
                  z
                  ′
                
                ,
                
                  z
                  ′
                
                
                  A
                  ′
                
                )
                +
                E
                (
                
                  z
                  ′
                
                )
                E
                (
                
                  z
                  ′
                
                
                  A
                  ′
                
                
                  )
                  ′
                
              
            
            
              
              
                
                =
                Cov
                ⁡
                (
                
                  z
                  ′
                
                ,
                
                  z
                  ′
                
                
                  A
                  ′
                
                )
                +
                
                  μ
                  ′
                
                (
                
                  μ
                  ′
                
                
                  A
                  ′
                
                
                  )
                  ′
                
              
            
            
              
              
                
                =
                Cov
                ⁡
                (
                
                  z
                  ′
                
                ,
                
                  z
                  ′
                
                
                  A
                  ′
                
                )
                +
                
                  μ
                  ′
                
                A
                μ
                ,
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}E(XY')&=\operatorname {Cov} (X,Y)+E(X)E(Y)'\\E(z'Az)&=\operatorname {Cov} (z',z'A')+E(z')E(z'A')'\\&=\operatorname {Cov} (z',z'A')+\mu '(\mu 'A')'\\&=\operatorname {Cov} (z',z'A')+\mu 'A\mu ,\end{aligned}}}
  что приводит нас к

  
    
      
        Cov
        ⁡
        (
        
          z
          ′
        
        ,
        
          z
          ′
        
        
          A
          ′
        
        )
        =
        tr
        ⁡
        (
        A
        V
        )
        .
      
    
    {\displaystyle \operatorname {Cov} (z',z'A')=\operatorname {tr} (AV).}
  Это верно в связи с тем, что при трассировке без изменения конечного результата можно циклически переставлять матрицы (например, tr (AB) = tr (BA)).
Мы видим, что ковариация

  
    
      
        
          
            
              
                Cov
                ⁡
                (
                
                  z
                  ′
                
                ,
                
                  z
                  ′
                
                
                  A
                  ′
                
                )
              
              
                
                =
                E
                
                  [
                  
                    
                      (
                      
                        
                          z
                          ′
                        
                        −
                        E
                        (
                        
                          z
                          ′
                        
                        )
                      
                      )
                    
                    
                      
                        (
                        
                          
                            z
                            ′
                          
                          
                            A
                            ′
                          
                          −
                          E
                          
                            (
                            
                              
                                z
                                ′
                              
                              
                                A
                                ′
                              
                            
                            )
                          
                        
                        )
                      
                      ′
                    
                  
                  ]
                
              
            
            
              
              
                
                =
                E
                
                  [
                  
                    (
                    
                      z
                      ′
                    
                    −
                    
                      μ
                      ′
                    
                    )
                    (
                    
                      z
                      ′
                    
                    
                      A
                      ′
                    
                    −
                    
                      μ
                      ′
                    
                    
                      A
                      ′
                    
                    
                      )
                      ′
                    
                  
                  ]
                
              
            
            
              
              
                
                =
                E
                
                  [
                  
                    (
                    z
                    −
                    μ
                    
                      )
                      ′
                    
                    (
                    A
                    z
                    −
                    A
                    μ
                    )
                  
                  ]
                
                .
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}\operatorname {Cov} (z',z'A')&=E\left[\left(z'-E(z')\right)\left(z'A'-E\left(z'A'\right)\right)'\right]\\&=E\left[(z'-\mu ')(z'A'-\mu 'A')'\right]\\&=E\left[(z-\mu )'(Az-A\mu )\right].\end{aligned}}}
  и затем

  
    
      
        
          
            (
            
              z
              −
              μ
            
            )
          
          ′
        
        
          (
          
            A
            z
            −
            A
            μ
          
          )
        
      
    
    {\displaystyle \left({z-\mu }\right)'\left({Az-A\mu }\right)}
  является скаляром, тогда

  
    
      
        (
        z
        −
        μ
        
          )
          ′
        
        (
        A
        z
        −
        A
        μ
        )
        =
        tr
        ⁡
        
          [
          
            (
            z
            −
            μ
            
              )
              ′
            
            (
            A
            z
            −
            A
            μ
            )
          
          ]
        
        =
        tr
        ⁡
        
          [
          
            (
            z
            −
            μ
            
              )
              ′
            
            A
            (
            z
            −
            μ
            )
          
          ]
        
      
    
    {\displaystyle (z-\mu )'(Az-A\mu )=\operatorname {tr} \left[{(z-\mu )'(Az-A\mu )}\right]=\operatorname {tr} \left[(z-\mu )'A(z-\mu )\right]}
  тривиально. Используя перестановку, получим:

  
    
      
        tr
        ⁡
        
          [
          
            (
            z
            −
            μ
            
              )
              ′
            
            A
            (
            z
            −
            μ
            )
          
          ]
        
        =
        tr
        ⁡
        
          [
          
            A
            (
            z
            −
            μ
            )
            (
            z
            −
            μ
            
              )
              ′
            
          
          ]
        
        ,
      
    
    {\displaystyle \operatorname {tr} \left[{(z-\mu )'A(z-\mu )}\right]=\operatorname {tr} \left[{A(z-\mu )(z-\mu )'}\right],}
  И, включив это в исходную формулу, получим:

  
    
      
        
          
            
              
                Cov
                ⁡
                
                  (
                  
                    
                      z
                      ′
                    
                    ,
                    
                      z
                      ′
                    
                    
                      A
                      ′
                    
                  
                  )
                
              
              
                
                =
                E
                
                  [
                  
                    
                      
                        (
                        
                          z
                          −
                          μ
                        
                        )
                      
                      ′
                    
                    (
                    A
                    z
                    −
                    A
                    μ
                    )
                  
                  ]
                
              
            
            
              
              
                
                =
                E
                
                  [
                  
                    tr
                    ⁡
                    
                      [
                      
                        A
                        (
                        z
                        −
                        μ
                        )
                        (
                        z
                        −
                        μ
                        
                          )
                          ′
                        
                      
                      ]
                    
                  
                  ]
                
              
            
            
              
              
                
                =
                tr
                ⁡
                
                  [
                  
                    A
                    ⋅
                    E
                    
                      [
                      
                        (
                        z
                        −
                        μ
                        )
                        (
                        z
                        −
                        μ
                        
                          )
                          ′
                        
                      
                      ]
                    
                  
                  ]
                
              
            
            
              
              
                
                =
                tr
                ⁡
                [
                A
                V
                ]
                .
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}\operatorname {Cov} \left({z',z'A'}\right)&=E\left[{\left({z-\mu }\right)'(Az-A\mu )}\right]\\&=E\left[\operatorname {tr} \left[A(z-\mu )(z-\mu )'\right]\right]\\&=\operatorname {tr} \left[{A\cdot E\left[(z-\mu )(z-\mu )'\right]}\right]\\&=\operatorname {tr} [AV].\end{aligned}}}

Математическое ожидание произведения двух разных квадратичных форм
Возьмем математическое ожидание произведения двух разных квадратичных форм в гауссовском случайном векторе X с нулевым средним следующим образом::стр. 162–176

  
    
      
        E
        ⁡
        [
        
          X
          
            T
          
        
        A
        X
        ]
        [
        
          X
          
            T
          
        
        B
        X
        ]
        =
        2
        tr
        ⁡
        (
        A
        C
        B
        C
        )
        +
        tr
        ⁡
        (
        A
        C
        )
        tr
        ⁡
        (
        B
        C
        )
      
    
    {\displaystyle \operatorname {E} [X^{T}AX][X^{T}BX]=2\operatorname {tr} (ACBC)+\operatorname {tr} (AC)\operatorname {tr} (BC)}
  Где снова C является ковариационной матрицей X. Опять же, поскольку обе квадратичные формы являются скалярами и, следовательно, их произведение является скаляром, математическое ожидание их произведения также является скаляром.

Векторный временной ряд
Эволюцию k × 1 случайного вектора 
  
    
      
        
          X
        
      
    
    {\displaystyle \mathbf {X} }
   во времени можно смоделировать как векторную авторегрессию (VAR) следующим образом:


== References ==