Информа́ция Фи́шера - математическое ожидание квадрата относительной скорости изменения условной плотности вероятности 
  
    
      
        p
        (
        θ
        ,
        x
        )
      
    
    {\displaystyle p(\theta ,x)}
   в точке 
  
    
      
        x
      
    
    {\displaystyle x}
  . Эта функция названа в 
честь описавшего её Рональда Фишера.

Определение
Пусть 
  
    
      
        f
        (
        θ
        ,
        
        
          x
          
            1
          
        
        ,
        …
        ,
        
        
          x
          
            n
          
        
        )
      
    
    {\displaystyle f(\theta ,\;x_{1},\dots ,\,x_{n})}
   — плотность распределения для данной статистической модели. Тогда если определена функция

  
    
      
        
          I
          
            n
          
        
        (
        θ
        )
        =
        
          
            E
          
          
            θ
          
        
        
          
            (
            
              
                
                  ∂
                  L
                  (
                  θ
                  ,
                  
                  
                    x
                    
                      1
                    
                  
                  ,
                  …
                  ,
                  
                  
                    x
                    
                      n
                    
                  
                  )
                
                
                  ∂
                  θ
                
              
            
            )
          
          
            2
          
        
        ,
        
        L
        =
        
          ∑
          
            i
            =
            1
          
          
            n
          
        
        ln
        ⁡
        f
        (
        θ
        ,
        
          x
          
            i
          
        
        )
      
    
    {\displaystyle I_{n}(\theta )=\mathbb {E} _{\theta }\left({\frac {\partial L(\theta ,\;x_{1},\dots ,\,x_{n})}{\partial \theta }}\right)^{2},\;L=\sum _{i=1}^{n}\ln f(\theta ,x_{i})}
  ,где 
  
    
      
        L
        (
        θ
        ,
        
        
          x
          
            1
          
        
        ,
        …
        ,
        
        
          x
          
            n
          
        
        )
      
    
    {\displaystyle L(\theta ,\;x_{1},\dots ,\,x_{n})}
   — логарифмическая функция правдоподобия, а 
  
    
      
        
          
            E
          
          
            θ
          
        
      
    
    {\displaystyle \mathbb {E} _{\theta }}
   — математическое ожидание при данном 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  , то она называется информацией Фишера для данной статистической модели при 
  
    
      
        n
      
    
    {\displaystyle n}
   независимых испытаниях.
Если 
  
    
      
        ln
        ⁡
        f
        (
        x
        ;
        θ
        )
      
    
    {\displaystyle \ln f(x;\theta )}
   дважды дифференцируем по 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  , и при определенных условиях регулярности, информацию Фишера можно переписать как 

  
    
      
        
          I
          
            n
          
        
        (
        θ
        )
        =
        
          
            E
          
          
            θ
          
        
        
          
            (
            
              
                
                  ∂
                  L
                  (
                  θ
                  ,
                  
                  X
                  )
                
                
                  ∂
                  θ
                
              
            
            )
          
          
            2
          
        
        =
        −
        
          
            E
          
          
            θ
          
        
        
          (
          
            
              
                
                  ∂
                  
                    2
                  
                
                L
                (
                θ
                ,
                
                X
                )
              
              
                ∂
                
                  θ
                  
                    2
                  
                
              
            
          
          )
        
      
    
    {\displaystyle I_{n}(\theta )=\mathbb {E} _{\theta }\left({\frac {\partial L(\theta ,\;X)}{\partial \theta }}\right)^{2}=-\mathbb {E} _{\theta }\left({\frac {\partial ^{2}L(\theta ,\;X)}{\partial \theta ^{2}}}\right)}
  Для регулярных моделей: 
  
    
      
        
          
            E
          
          
            θ
          
        
        
          (
          
            
              
                ∂
                L
                (
                θ
                ,
                
                
                  x
                  
                    1
                  
                
                ,
                …
                ,
                
                
                  x
                  
                    n
                  
                
                )
              
              
                ∂
                θ
              
            
          
          )
        
        =
        0
      
    
    {\displaystyle \mathbb {E} _{\theta }\left({\frac {\partial L(\theta ,\;x_{1},\dots ,\,x_{n})}{\partial \theta }}\right)=0}
   (В этом и состоит определение регулярности).
В этом случае, поскольку математическое ожидание функции вклада выборки равно нулю, выписанная величина равна её дисперсии.
Фишеровским количеством информации, содержащемся в одном наблюдении называют:

  
    
      
        
          I
          
            i
          
        
        (
        θ
        )
        =
        
          
            E
          
          
            θ
          
        
        
          
            (
            
              
                
                  ∂
                  ln
                  ⁡
                  f
                  (
                  θ
                  ,
                  
                  
                    x
                    
                      i
                    
                  
                  )
                
                
                  ∂
                  θ
                
              
            
            )
          
          
            2
          
        
      
    
    {\displaystyle I_{i}(\theta )=\mathbb {E} _{\theta }\left({\frac {\partial \ln f(\theta ,\,x_{i})}{\partial \theta }}\right)^{2}}
  .Для регулярных моделей все 
  
    
      
        
          I
          
            i
          
        
        (
        θ
        )
      
    
    {\displaystyle I_{i}(\theta )}
   равны между собой.
Если выборка состоит из одного элемента, то информация Фишера записывается так:

  
    
      
        I
        (
        θ
        )
        =
        
          
            E
          
          
            θ
          
        
        
          
            (
            
              
                
                  ∂
                  ln
                  ⁡
                  f
                  (
                  θ
                  ,
                  
                  x
                  )
                
                
                  ∂
                  θ
                
              
            
            )
          
          
            2
          
        
      
    
    {\displaystyle I(\theta )=\mathbb {E} _{\theta }\left({\frac {\partial \ln f(\theta ,\,x)}{\partial \theta }}\right)^{2}}
  .Из условия регулярности, а также из того, что в случае независимости случайных величин дисперсия суммы равна сумме дисперсий, следует, что для 
  
    
      
        n
      
    
    {\displaystyle n}
   независимых испытаний 
  
    
      
        
          I
          
            n
          
        
        (
        θ
        )
        =
        n
        I
        (
        θ
        )
      
    
    {\displaystyle I_{n}(\theta )=nI(\theta )}
  .

Свойства
Из указанного выше свойства дисперсий следует, что в случае независимости случайных величин 
  
    
      
        
          ξ
          
            1
          
        
        (
        θ
        ,
        
        x
        )
        ,
        …
        ,
        
        
          ξ
          
            n
          
        
        (
        θ
        ,
        
        x
        )
      
    
    {\displaystyle \xi _{1}(\theta ,\,x),\dots ,\,\xi _{n}(\theta ,\,x)}
   (рассматриваемых в одной статистической модели) информация Фишера их суммы равна сумме информации Фишера каждой из них.

Сохранение информации достаточной статистикой
В общем случае, если 
  
    
      
        T
        =
        t
        (
        X
        )
      
    
    {\displaystyle T=t(X)}
   — статистика выборки X, то 

  
    
      
        
          I
          
            T
          
        
        (
        θ
        )
        ≤
        
          I
          
            X
          
        
        (
        θ
        )
      
    
    {\displaystyle I_{T}(\theta )\leq I_{X}(\theta )}
  Причем равенство достигается тогда и только тогда, когдаT является достаточной статистикой.
Достаточная статистика содержит столько же информации Фишера, сколько и вся выборка X. 
Это может быть показано с помощью факторизационного критерия Неймана для достаточной статистики. Если статистика 
  
    
      
        T
        (
        X
        )
      
    
    {\displaystyle T(X)}
   достаточна для параметра θ, то существуют функции g и h такие, что:

  
    
      
        f
        (
        X
        ;
        θ
        )
        =
        g
        (
        T
        (
        X
        )
        ,
        θ
        )
        h
        (
        X
        )
      
    
    {\displaystyle f(X;\theta )=g(T(X),\theta )h(X)}
  Равенство информации следует из:

  
    
      
        
          
            ∂
            
              ∂
              θ
            
          
        
        ln
        ⁡
        
          [
          
            f
            (
            X
            ;
            θ
            )
          
          ]
        
        =
        
          
            ∂
            
              ∂
              θ
            
          
        
        ln
        ⁡
        
          [
          
            g
            (
            T
            (
            X
            )
            ;
            θ
            )
          
          ]
        
      
    
    {\displaystyle {\frac {\partial }{\partial \theta }}\ln \left[f(X;\theta )\right]={\frac {\partial }{\partial \theta }}\ln \left[g(T(X);\theta )\right]}
  что следует из определения информации Фишера и независимости 
  
    
      
        h
        (
        X
        )
      
    
    {\displaystyle h(X)}
   от θ.

См. также
Неравенство Крамера — Рао
Информационное неравенство (математическая статистика)Другие меры, используемые в теории информации:

Информационная энтропия
Расстояние Кульбака — Лейблера
Собственная информация

Примечания
Литература
Леман Э. Теория точечного оценивания. — М.: Наука, 1991. — 448 с. — ISBN 5-02-013941-6.