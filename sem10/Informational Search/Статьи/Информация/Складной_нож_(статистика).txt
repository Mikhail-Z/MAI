Складной нож (англ. jackknife) — один из методов ресэмплинга (линейное приближением статистического бутстрэпа), используемый для оценки погрешности в статистическом выводе. Способ заключается в следующем: для каждого элемента вычисляется среднее значение выборки без учёта данного элемента, а затем — среднее всех таких значений. Для выборки из N элементов оценка получается путём вычисления среднего значения остальных N-1 элементов. 
Этот метод разработал Морис Кенуй (Maurice Quenouille 1949, 1956) с целью уменьшения погрешности оценки отдельного образца. Джон Тьюки в 1958 году расширил его возможности и предложил название «складной нож», потому что его действие напоминает складной нож — простой инструмент, которым можно решить множество различных проблем, пускай и менее эффективно, чем при помощи предназначенных для этого средств. Он может помочь улучшить оценку в случае когда данные распределены неравномерно.

Оценка
Оценочные параметры могут быть найдены как среднее значение элементов выборки без i-го элемента (назовем их 
  
    
      
        
          
            
              
                x
                ¯
              
            
          
          
            i
          
        
      
    
    {\displaystyle {\bar {x}}_{i}}
  ).

  
    
      
        
          
            
              
                
                  
                    x
                    ¯
                  
                
              
              
                i
              
            
            =
            
              
                1
                
                  n
                  −
                  1
                
              
            
            
              ∑
              
                j
                ≠
                i
              
              
                n
              
            
            
              x
              
                j
              
            
          
        
      
    
    {\displaystyle {\displaystyle {\bar {x}}_{i}={\frac {1}{n-1}}\sum _{j\neq i}^{n}x_{j}}}

Дисперсионная оценка
Оценка дисперсии параметров может быть вычислена по формуле:

  
    
      
        
          Var
          
            
              (
              j
              a
              c
              k
              k
              n
              i
              f
              e
              )
            
          
        
        =
        
          
            
              n
              −
              1
            
            n
          
        
        
          ∑
          
            i
            =
            1
          
          
            n
          
        
        (
        
          
            
              
                x
                ¯
              
            
          
          
            i
          
        
        −
        
          
            
              
                x
                ¯
              
            
          
          
            
              (
              .
              )
            
          
        
        
          )
          
            2
          
        
        =
        
          
            1
            n
          
        
        ⋅
        
          ∑
          
            i
            =
            1
          
          
            n
          
        
        (
        
          
            
              
                ∑
                
                  j
                  =
                  1
                
                
                  n
                
              
              
                x
                
                  j
                
              
            
            n
          
        
        −
        
          x
          
            i
          
        
        
          )
          
            2
          
        
      
    
    {\displaystyle \operatorname {Var} _{\mathrm {(jackknife)} }={\frac {n-1}{n}}\sum _{i=1}^{n}({\bar {x}}_{i}-{\bar {x}}_{\mathrm {(.)} })^{2}={\frac {1}{n}}\cdot \sum \limits _{i=1}^{n}({\frac {\sum \limits _{j=1}^{n}x_{j}}{n}}-x_{i})^{2}}
  
где 
  
    
      
        
          
            
              
                x
                ¯
              
            
          
          
            i
          
        
      
    
    {\displaystyle {\bar {x}}_{i}}
   — это оценочные параметры, а 
  
    
      
        
          
            
              
                
                  
                    x
                    ¯
                  
                
              
              
                
                  (
                  .
                  )
                
              
            
            =
            
              
                1
                n
              
            
            
              ∑
              
                i
              
              
                n
              
            
            
              
                
                  
                    x
                    ¯
                  
                
              
              
                i
              
            
          
        
      
    
    {\displaystyle {\displaystyle {\bar {x}}_{\mathrm {(.)} }={\frac {1}{n}}\sum _{i}^{n}{\bar {x}}_{i}}}
   — оценка, основанная на всех элементах.
Другими словами оценка дисперсии — это среднее арифметическое квадратов разности среднего арифметического всех элементов и данного.

Оценка и коррекция смещения
Данный метод может быть использован для оценки погрешности параметра относительно всей выборки. Введем 
  
    
      
        
          
            
              
                
                  θ
                  ^
                
              
            
          
        
      
    
    {\displaystyle {\displaystyle {\hat {\theta }}}}
  , как оценку параметра на основе всех данных:

  
    
      
        
          
            
              θ
              ^
            
          
        
        =
        
          
            
              Var
              
                
                  (
                  j
                  a
                  c
                  k
                  k
                  n
                  i
                  f
                  e
                  )
                
              
            
            
              n
              −
              1
            
          
        
      
    
    {\displaystyle {\hat {\theta }}={\frac {\operatorname {Var} _{\mathrm {(jackknife)} }}{n-1}}}
  

  
    
      
        
          
            
              
                θ
                ^
              
            
          
          
            
              (
              .
              )
            
          
        
        =
        
          
            1
            n
          
        
        
          ∑
          
            i
            =
            1
          
          
            n
          
        
        
          
            
              
                θ
                ^
              
            
          
          
            
              (
              i
              )
            
          
        
      
    
    {\displaystyle {\hat {\theta }}_{\mathrm {(.)} }={\frac {1}{n}}\sum _{i=1}^{n}{\hat {\theta }}_{\mathrm {(i)} }}
  

  
    
      
        
          
            
              
                
                  
                    Bias
                    ^
                  
                
              
              
                
                  (
                  θ
                  )
                
              
            
            =
            (
            n
            −
            1
            )
            (
            
              
                
                  
                    θ
                    ^
                  
                
              
              
                
                  (
                  .
                  )
                
              
            
            −
            
              
                
                  θ
                  ^
                
              
            
            )
          
        
      
    
    {\displaystyle {\displaystyle {\widehat {\text{Bias}}}_{\mathrm {(\theta )} }=(n-1)({\hat {\theta }}_{\mathrm {(.)} }-{\hat {\theta }})}}