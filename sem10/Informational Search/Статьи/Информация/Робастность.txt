Робастность (англ. robustness, от robust — «крепкий», «сильный», «твёрдый», «устойчивый») — свойство статистического метода, характеризующее независимость влияния на результат исследования различного рода выбросов, устойчивости к помехам. Выбросоустойчивый (робастный) метод — метод, направленный на выявление выбросов, снижение их влияния или исключение их из выборки.
На практике наличие в выборках даже небольшого числа резко выделяющихся наблюдений (выбросов) способно сильно повлиять на результат исследования, например, метод наименьших квадратов и метод максимального правдоподобия на специфических распределениях подвержены такого рода искажениям, и значения, получаемые в результате исследования, могут перестать нести в себе какой-либо смысл. Для исключения влияния таких помех используются различные подходы для снижения влияния «плохих» наблюдений (выбросов), либо полного их исключения. Основная задача выбросоустойчивых методов — отличить «плохое» наблюдение от «хорошего», притом даже самый простой из подходов — субъективный (основанный на внутренних ощущениях исследователя) — может принести значительную пользу, однако для мотивированной отбраковки все же исследователями применяются методы, имеющие в своей основе некие строгие математические обоснования. Этот процесс представляет собой весьма нетривиальную задачу для статистика и определяет собой одно из направлений статистической науки.

Понятие выбросоустойчивости (робастности)
Под выбросоустойчивостью (робастностью) в статистике понимают чувствительность к различным отклонениям и неоднородностям в выборке, связанным с теми или иными, в общем случае неизвестными, причинами. Это могут быть ошибки детектора, регистрирующего наблюдения, чьи-то добросовестные или намеренные попытки «подогнать» выборку до того, как она попадёт к статистику, ошибки оформления, вкравшиеся опечатки и многое другое. Например, наиболее выбросоустойчивой оценкой параметра сдвига закона распределения является медиана, что на интуитивном уровне вполне очевидно (для строгого доказательства следует воспользоваться тем, что медиана является усечённой М-оценкой, см. ниже). Помимо непосредственно «бракованных» наблюдений, также может присутствовать некоторое количество наблюдений, подчиняющихся другому распределению. Ввиду условности законов распределений, а это не более, чем модели описания, сама по себе выборка может содержать некоторые расхождения с идеалом.
Тем не менее, параметрический подход настолько вжился, доказав свою простоту и целесообразность, что нелепо от него отказываться. Поэтому и возникла необходимость приспособить старые модели к новым задачам.
Стоит отдельно подчеркнуть и не забывать, что отбракованные наблюдения нуждаются в отдельном, более пристальном внимании. Наблюдения, кажущиеся «плохими» для одной гипотезы, могут вполне соответствовать другой. Наконец, отнюдь не всегда резко выделяющиеся наблюдения являются «браком». Одно такое наблюдение для генной инженерии, к примеру, стоит миллионов других, мало отличающихся друг от друга.

Основные подходы
Для того, чтобы ограничить влияние неоднородностей, либо вовсе его исключить, существует множество различных подходов. Среди них выделяются два основных направления.

Группировка данных без удаления отдельных наблюдений (для снижения возможности порчи выборки отдельными выпадами). После чего с достаточной степенью уверенности допустимо использование классических методов статистики.Отслеживание выбросов непосредственно в процессе анализа. Например, для определения параметров закона распределения возможно использование итерационной процедуры с усечёнными или th-сниженными M-оценками.

Группирование данных как метод выбросоустойчивой статистики
Посредством группирования выборки можно резко снизить влияние отдельных наблюдений, не отбрасывая их. Разбиение на интервалы не представляет особых трудностей и даёт весьма ощутимый результат. Существует три наиболее распространённых способа разбиения.

Разбиение на интервалы равной длины. Наиболее простой и потому распространённый способ.Разбиение на интервалы равной вероятности, также называемое равночастотным группированием, что отражает практическую реализацию этого метода. В результате такого группирования выборки осуществляется максимизация величины информационной энтропии 
  
    
      
        ∑
        
          −
          
            P
            
              i
            
          
        
        ln
        ⁡
        
          
            P
            
              i
            
          
        
      
    
    {\displaystyle \sum {-P_{i}}\ln {P_{i}}}
  , где 
  
    
      
        
          P
          
            i
          
        
        =
        
          ∫
          
            
              x
              
                i
                −
                1
              
            
          
          
            
              x
              
                i
              
            
          
        
        f
        (
        x
        )
        
        
          d
        
        x
      
    
    {\displaystyle P_{i}=\int \limits _{x_{i-1}}^{x_{i}}f(x)\,\mathrm {d} x}
   и достигается наибольшая асимптотическая мощность критерия согласия 
  
    
      
        
          χ
          
            2
          
        
      
    
    {\displaystyle \chi ^{2}}
  , либо критерия отношения правдоподобия.Разбиение на асимптотически оптимальные интервалы. При таком разбиении минимизируются потери информации в результате группирования, то есть максимизируется фишеровская информация 
  
    
      
        ∑
        
          
            (
            
              
                
                  ∂
                  ln
                  ⁡
                  
                    P
                    
                      i
                    
                  
                
                
                  ∂
                  θ
                
              
            
            )
          
          
            2
          
        
        
          P
          
            i
          
        
      
    
    {\displaystyle \sum \left({\frac {\partial \ln P_{i}}{\partial \theta }}\right)^{2}P_{i}}
  , где 
  
    
      
        θ
      
    
    {\displaystyle \theta }
   — оцениваемый параметр закона. Для многих законов распределения удалось получить инвариантные относительно параметров границы интервалов, и были составлены соответствующие таблицы. Такое разбиение позволяет максимизировать мощность критерия.

Подход, основанный на функции влияния
Отдельный подход в построении выбросоустойчивых методов — оценивание параметров закона распределения по «засорённой» выборке с использованием подхода, предложенного Хампелем. Для того, чтобы изучить влияние отдельно взятого наблюдения на оценку (рассматриваемую статистику) того или иного параметра закона распределения, Хампелем вводится так называемая функция влияния (англ. influence function), которая представляет собой не что иное, как производную этой статистики.

Основные понятия
Вводится функционал 
  
    
      
        T
      
    
    {\displaystyle T}
  , как функция от некоторой выборки

  
    
      
        X
        =
        (
        
          X
          
            1
          
        
        …
        
          X
          
            n
          
        
        )
        ∈
        
          X
        
      
    
    {\displaystyle X=(X_{1}\ldots X_{n})\in \mathbb {X} }
  
из распределения 
  
    
      
        F
      
    
    {\displaystyle F}
   c параметром 
  
    
      
        θ
        ∈
        Θ
      
    
    {\displaystyle \theta \in \Theta }
   (оно же 
  
    
      
        
          F
          
            θ
          
        
      
    
    {\displaystyle F_{\theta }}
  ). 
  
    
      
        T
      
    
    {\displaystyle T}
   зависит от

  
    
      
        X
        :
        
          F
          
            θ
          
        
      
    
    {\displaystyle X:F_{\theta }}
  . Значит 
  
    
      
        T
      
    
    {\displaystyle T}
   является функцией от закона 
  
    
      
        F
      
    
    {\displaystyle F}
   и от параметра 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  . Пусть 
  
    
      
        T
      
    
    {\displaystyle T}
   также удовлетворяет некоторым условиям состоятельности и регулярности:

  
    
      
        T
        (
        F
        )
        =
        θ
        ,
        
        ∫
        T
        
        
          d
        
        F
        =
        0.
      
    
    {\displaystyle T(F)=\theta ,\quad \int T\,\mathrm {d} F=0.}
  Производная этого функционала 
  
    
      
        T
      
    
    {\displaystyle T}
   в точке с распределением 
  
    
      
        F
      
    
    {\displaystyle F}
  :

  
    
      
        ∃
        
        a
        :
        
        
          lim
          
            t
            →
            0
          
        
        
          
            
              T
              (
              (
              1
              −
              t
              )
              F
              +
              t
              G
              )
              −
              T
              (
              F
              )
            
            t
          
        
        :=
        ∫
        a
        
        
          d
        
        G
        ,
      
    
    {\displaystyle \exists \,a:\quad \lim _{t\to 0}{\frac {T((1-t)F+tG)-T(F)}{t}}:=\int a\,\mathrm {d} G,}
  где:

  
    
      
        a
      
    
    {\displaystyle a}
   — некая функция, смысл которой прояснится на следующем шаге;

  
    
      
        G
      
    
    {\displaystyle G}
   — некий закон распределения, отличный от 
  
    
      
        F
      
    
    {\displaystyle F}
  .При подстановке 
  
    
      
        
          Δ
          
            x
          
        
      
    
    {\displaystyle \Delta _{x}}
  , приписывающей единичную массу событию 
  
    
      
        X
        =
        x
      
    
    {\displaystyle X=x}
  , вместо 
  
    
      
        G
      
    
    {\displaystyle G}
  , в результате чего от интеграла в правой части выражения останется только 
  
    
      
        a
        (
        x
        )
      
    
    {\displaystyle a(x)}
  :

  
    
      
        I
        F
        =
        
          lim
          
            t
            →
            0
          
        
        
          
            
              T
              (
              (
              1
              −
              t
              )
              F
              +
              t
              
                Δ
                
                  x
                
              
              )
              −
              T
              (
              F
              )
            
            t
          
        
        .
      
    
    {\displaystyle IF=\lim _{t\to 0}{\frac {T((1-t)F+t\Delta _{x})-T(F)}{t}}.}
  Эту функцию и называют функцией влияния.
Смысл функции влияния демонстрируется подстановкой 
  
    
      
        
          
            1
            n
          
        
      
    
    {\displaystyle {\frac {1}{n}}}
   вместо 
  
    
      
        t
      
    
    {\displaystyle t}
   и заменой предела, в результате выражение 
  
    
      
        
          F
          
            t
            ,
            x
          
        
        =
        (
        1
        −
        t
        )
        F
        +
        t
        
          Δ
          
            x
          
        
      
    
    {\displaystyle F_{t,x}=(1-t)F+t\Delta _{x}}
   преобразуется в

  
    
      
        
          F
          
            
              
                1
                n
              
            
            ,
            x
          
        
        =
        
          
            
              (
              n
              −
              1
              )
              F
              +
              
                Δ
                
                  x
                
              
            
            n
          
        
      
    
    {\displaystyle F_{{\frac {1}{n}},x}={\frac {(n-1)F+\Delta _{x}}{n}}}
  ,
что соответствует ситуации, когда в выборку, состоящую из 
  
    
      
        (
        n
        −
        1
        )
      
    
    {\displaystyle (n-1)}
   наблюдения, подчиняющихся распределению 
  
    
      
        F
      
    
    {\displaystyle F}
  , добавляют ещё одно новое. Таким образом 
  
    
      
        I
        F
      
    
    {\displaystyle IF}
   отслеживает реакцию используемого функционала 
  
    
      
        T
      
    
    {\displaystyle T}
   на внесённое добавление, показывая влияние от вклада отдельного наблюдения 
  
    
      
        x
      
    
    {\displaystyle x}
   на оценку по всей совокупности данных.
Для характеристики влияния отдельных наблюдений также вводят понятие чувствительности к большой ошибке 
  
    
      
        γ
      
    
    {\displaystyle \gamma }
   :

  
    
      
        γ
        =
        
          sup
          
            x
            ∈
            
              X
            
          
        
        
          |
        
        I
        F
        (
        x
        )
        
          |
        
        .
      
    
    {\displaystyle \gamma =\sup _{x\in \mathbb {X} }|IF(x)|.}
  Если функция влияния ограничена, то соответствующую оценку называют B(бэ)-робастной.

М-оценки
Наиболее эффективными и широко используемыми оценками параметров законов распределений являются оценки максимального правдоподобия (ОМП), которые определяются одним из следующих условий:

  
    
      
        
          ∑
          
            i
          
        
        ln
        ⁡
        
          P
          
            i
          
        
        →
        
          max
          
            θ
            ∈
            Θ
          
        
        ,
        
        
          ∑
          
            i
          
        
        
          
            
              ∂
              ln
              ⁡
              
                P
                
                  i
                
              
            
            
              ∂
              θ
            
          
        
        =
        0
        ,
        
        
          ∑
          
            i
          
        
        
          
            
              P
              
                i
              
              ′
            
            
              P
              
                i
              
            
          
        
        =
        0
        ,
      
    
    {\displaystyle \sum _{i}\ln P_{i}\to \max _{\theta \in \Theta },\qquad \sum _{i}{\frac {\partial \ln P_{i}}{\partial \theta }}=0,\qquad \sum _{i}{\frac {P_{i}'}{P_{i}}}=0,}
  где в случае негруппированной выборки 
  
    
      
        
          P
          
            i
          
        
        =
        f
        (
        
          x
          
            i
          
        
        ,
        θ
        )
      
    
    {\displaystyle P_{i}=f(x_{i},\theta )}
  , а в случае группированной — 
  
    
      
        
          P
          
            i
          
        
        =
        
          
            (
            
              
                ∫
                
                  
                    x
                    
                      i
                      −
                      1
                    
                  
                
                
                  
                    x
                    
                      i
                    
                  
                
              
              f
              (
              x
              ,
              θ
              )
              
              
                d
              
              x
            
            )
          
          
            
              n
              
                i
              
            
          
        
      
    
    {\displaystyle P_{i}=\left(\int \limits _{x_{i-1}}^{x_{i}}f(x,\theta )\,\mathrm {d} x\right)^{n_{i}}}
  
М-оценки — есть некое обобщение ОМП. Они определяются аналогично одним из соотношений:

  
    
      
        
          ∑
          
            i
            =
            1
          
          
            N
          
        
        ρ
        (
        
          x
          
            i
          
        
        ,
        θ
        )
        →
        
          max
          
            θ
            ∈
            Θ
          
        
        ,
        
        
          ∑
          
            i
            =
            1
          
          
            N
          
        
        ϕ
        (
        
          x
          
            i
          
        
        ,
        θ
        )
        =
        0.
      
    
    {\displaystyle \sum _{i=1}^{N}\rho (x_{i},\theta )\to \max _{\theta \in \Theta },\qquad \sum _{i=1}^{N}\phi (x_{i},\theta )=0.}
  Если наложить условие регулярности в подстановке 
  
    
      
        
          F
          
            t
            ,
            x
          
        
        =
        (
        1
        −
        t
        )
        F
        +
        t
        
          Δ
          
            x
          
        
      
    
    {\displaystyle F_{t,x}=(1-t)F+t\Delta _{x}}
   и продифференцировать его по 
  
    
      
        t
      
    
    {\displaystyle t}
   в 0:

  
    
      
        0
        =
        
          
            ∂
            
              ∂
              
                t
              
            
          
        
        ∫
        ϕ
        (
        x
        ,
        T
        (
        
          F
          
            t
            ,
            x
          
        
        )
        )
        
        
          d
        
        
          F
          
            t
            ,
            x
          
        
      
    
    {\displaystyle 0={\frac {\partial }{\partial {t}}}\int \phi (x,T(F_{t,x}))\,\mathrm {d} F_{t,x}}
  
  
    
      
        0
        =
        ∫
        
          
            
              ∂
              ϕ
              (
              x
              ,
              T
              (
              
                F
                
                  t
                  ,
                  x
                
              
              )
              )
            
            
              ∂
              θ
            
          
        
        I
        F
        
        
          d
        
        
          F
          
            t
            ,
            x
          
        
        +
        ∫
        ϕ
        (
        x
        ,
        T
        (
        
          F
          
            t
            ,
            x
          
        
        )
        )
        
        
          d
        
        
          
            
              ∂
              (
              (
              1
              −
              t
              )
              F
              +
              t
              
                Δ
                
                  x
                
              
              )
            
            
              ∂
              t
            
          
        
      
    
    {\displaystyle 0=\int {\frac {\partial \phi (x,T(F_{t,x}))}{\partial \theta }}IF\,\mathrm {d} F_{t,x}+\int \phi (x,T(F_{t,x}))\,\mathrm {d} {\frac {\partial ((1-t)F+t\Delta _{x})}{\partial t}}}
  
  
    
      
        0
        =
        I
        F
        ∫
        
          
            
              ∂
              ϕ
              (
              x
              ,
              T
              (
              
                F
                
                  t
                  ,
                  x
                
              
              )
              )
            
            
              ∂
              θ
            
          
        
        
        
          d
        
        
          F
          
            t
            ,
            x
          
        
        +
        ϕ
        (
        x
        ,
        T
        (
        
          F
          
            t
            ,
            x
          
        
        )
        )
        ,
      
    
    {\displaystyle 0=IF\int {\frac {\partial \phi (x,T(F_{t,x}))}{\partial \theta }}\,\mathrm {d} F_{t,x}+\phi (x,T(F_{t,x})),}
  то не представляет большого труда получить выражение функции влияния для M-оценок:

  
    
      
        I
        F
        =
        
          
            
              −
              ϕ
              (
              x
              )
            
            
              ∫
              
                ϕ
                
                  θ
                
                ′
              
              (
              x
              )
              
              
                d
              
              F
            
          
        
        .
      
    
    {\displaystyle IF={\frac {-\phi (x)}{\int \phi '_{\theta }(x)\,\mathrm {d} F}}.}
  Указанное выражение позволяет сделать вывод о том, что M-оценки эквивалентны с точностью до ненулевого множителя-константы.

Несложно проверить, что для ОМП стандартного нормального закона распределения 
  
    
      
        
          
            N
          
        
        (
        0
        ,
        1
        )
      
    
    {\displaystyle {\mathcal {N}}(0,1)}
   функции влияния 
  
    
      
        I
        F
      
    
    {\displaystyle IF}
   параметра сдвига и параметра масштаба выглядят соответственно:

  
    
      
        I
        F
        =
        x
        ,
        
        I
        F
        =
        
          
            1
            2
          
        
        
        
          x
          
            2
          
        
        −
        
          
            1
            2
          
        
        .
      
    
    {\displaystyle IF=x,\quad IF={\frac {1}{2}}\;x^{2}-{\frac {1}{2}}.}
  Эти функции неограничены, а это значит, что ОМП не является выбросоустойчивой (робастной) в терминах B-робастности.
Для того, чтобы это исправить, M-оценки искусственно ограничивают, а значит, и ограничивают её 
  
    
      
        I
        F
      
    
    {\displaystyle IF}
   (см. выражение 
  
    
      
        I
        F
      
    
    {\displaystyle IF}
   для M-оценок), устанавливая верхний барьер на влияние резко выделяющихся (далеко отстоящих от предполагаемых значений параметров) наблюдений. Делается это введением так называемых усечённых M-оценок, определяемых выражением:

  
    
      
        
          ϕ
          
            b
          
        
        (
        z
        )
        =
        
          {
          
            
              
                
                  ϕ
                  (
                  b
                  )
                  ,
                
                
                  b
                  <
                  z
                
              
              
                
                  ϕ
                  (
                  z
                  )
                  ,
                
                
                  −
                  b
                  <
                  z
                  ⩽
                  b
                
              
              
                
                  ϕ
                  (
                  −
                  b
                  )
                  ,
                
                
                  z
                  ⩽
                  −
                  b
                
              
            
          
          }
        
        ,
      
    
    {\displaystyle \phi _{b}(z)=\left\{{\begin{array}{lr}\phi (b),&b<z\\\phi (z),&-b<z\leqslant b\\\phi (-b),&z\leqslant -b\end{array}}\right\},}
  где 
  
    
      
        z
        =
        
          
            
              x
              −
              θ
            
            S
          
        
      
    
    {\displaystyle z={\frac {x-\theta }{S}}}
  , 
  
    
      
        θ
      
    
    {\displaystyle \theta }
   и 
  
    
      
        S
      
    
    {\displaystyle S}
   — оценки параметров сдвига и масштаба соответственно.
Среди усечённых M-оценок оптимальными с точки зрения B-робастности являются усечённые ОМП.

Процедура оценивания параметров
Чтобы решить уравнение

  
    
      
        
          ∑
          
            i
            =
            1
          
          
            N
          
        
        ϕ
        (
        
          x
          
            i
          
        
        ,
        θ
        )
        =
        0
      
    
    {\displaystyle \sum _{i=1}^{N}\phi (x_{i},\theta )=0}
  ,необходимо воспользоваться каким-либо численным методом. Для этого понадобится выбрать начальные приближения. Нулевым параметром сдвига обычно служит медиана, параметром масштаба — значение, кратное медиане отклонений от медианы.
Например, если необходимо оценить параметр сдвига, скажем, нормального закона распределения, можно воспользоваться методом Ньютона численного нахождения корней уравнения. В результате вся процедура нахождения параметра сводится к итеративному вычислению выражения:

  
    
      
        
          θ
          
            k
            +
            1
          
        
        =
        
          θ
          
            k
          
        
        −
        
          
            
              
                ∑
                
                  i
                  =
                  1
                
                
                  N
                
              
              ϕ
              (
              
                x
                
                  i
                
              
              ,
              
                θ
                
                  k
                
              
              )
            
            
              
                ∑
                
                  i
                  =
                  1
                
                
                  N
                
              
              
                ϕ
                
                  θ
                
                ′
              
              (
              
                x
                
                  i
                
              
              ,
              
                θ
                
                  k
                
              
              )
            
          
        
        =
        
          θ
          
            k
          
        
        −
        
          
            
              
                ∑
                
                  i
                  =
                  1
                
                
                  N
                
              
              ϕ
              
                (
                
                  (
                  
                    x
                    
                      i
                    
                  
                  −
                  
                    θ
                    
                      k
                    
                  
                  )
                  
                    /
                  
                  S
                
                )
              
            
            
              
                ∑
                
                  i
                  =
                  1
                
                
                  N
                
              
              
                ϕ
                
                  θ
                
                ′
              
              
                (
                
                  (
                  
                    x
                    
                      i
                    
                  
                  −
                  
                    θ
                    
                      k
                    
                  
                  )
                  
                    /
                  
                  S
                
                )
              
            
          
        
        =
        
          θ
          
            k
          
        
        +
        S
        
          
            
              
                ∑
                
                  i
                  =
                  1
                
                
                  N
                
              
              ϕ
              
                (
                z
                )
              
            
            
              
                ∑
                
                  i
                  =
                  1
                
                
                  N
                
              
              
                ϕ
                
                  z
                
                ′
              
              
                (
                z
                )
              
            
          
        
        ,
      
    
    {\displaystyle \theta _{k+1}=\theta _{k}-{\frac {\sum _{i=1}^{N}\phi (x_{i},\theta _{k})}{\sum _{i=1}^{N}\phi '_{\theta }(x_{i},\theta _{k})}}=\theta _{k}-{\frac {\sum _{i=1}^{N}\phi \left((x_{i}-\theta _{k})/S\right)}{\sum _{i=1}^{N}\phi '_{\theta }\left((x_{i}-\theta _{k})/S\right)}}=\theta _{k}+S{\frac {\sum _{i=1}^{N}\phi \left(z\right)}{\sum _{i=1}^{N}\phi '_{z}\left(z\right)}},}
  где 
  
    
      
        S
      
    
    {\displaystyle S}
   — некоторая оценка параметра масштаба, используемая для уравнивания распределения с разным размахом.

См. также
Переобучение
Теорема Марелье

Примечания
Ссылки
Додонов Ю. С., Додонова Ю. А. Устойчивые меры центральной тенденции: взвешивание как возможная альтернатива усечению данных при анализе времен ответов.
Публикации по выбросоустойчивым (робастным) методам оценивания параметров и проверке статистических гипотез на сайте профессора НГТУ Лемешко Б. Ю.

Литература
Robert G. Staudte: Robust estimation and testing. Wiley, New York 1990. ISBN 0-471-85547-2
Rand R. Wilcox: Introduction to robust estimation and hypothesis testing. Academic Press, San Diego Cal 1997. ISBN 0-12-751545-3