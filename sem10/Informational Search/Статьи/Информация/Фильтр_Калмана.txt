Фи́льтр Ка́лмана — эффективный рекурсивный фильтр, оценивающий вектор состояния динамической системы, используя ряд неполных и зашумленных измерений. Назван в честь Рудольфа Калмана.
Фильтр Калмана широко используется в инженерных и эконометрических приложениях: от радаров и систем технического зрения до оценок параметров макроэкономических моделей. Калмановская фильтрация является важной частью теории управления, играет большую роль в создании систем управления. Совместно с линейно-квадратичным регулятором фильтр Калмана позволяет решить задачу линейно-квадратичного гауссовского управления. Фильтр Калмана и линейно-квадратичный регулятор — возможное решение большинства фундаментальных задач в теории управления.
В большинстве приложений размерность вектора состояния объекта превосходит размерность вектора данных наблюдения. И при этом фильтр Калмана позволяет оценивать полное внутреннее состояние объекта.
Фильтр Калмана предназначен для рекурсивного дооценивания вектора состояния априорно известной динамической системы, то есть для расчёта текущего состояния системы необходимо знать текущее измерение, а также предыдущее состояние самого фильтра. Таким образом, фильтр Калмана, подобно другим рекурсивным фильтрам, реализован во временно́м, а не в частотном представлении, но в отличие от других подобных фильтров, фильтр Калмана оперирует не только оценками состояния, а ещё и оценками неопределённости (плотности распределения) вектора состояния, опираясь на формулу Байеса условной вероятности.
Алгоритм работает в два этапа. На этапе прогнозирования фильтр Калмана экстраполирует значения переменных состояния, а также их неопределённости. На втором этапе по данным измерения (полученного с некоторой погрешностью) результат экстраполяции уточняется. Благодаря пошаговой природе алгоритма, он может в реальном времени отслеживать состояние объекта (без заглядывания вперед, используя только текущие замеры и информацию о предыдущем состоянии и его неопределенности).
Бытует ошибочное мнение, что для правильной работы фильтра Калмана якобы требуется гауссовское распределение входных данных. В исходной работе Калмана результаты о минимуме ковариации фильтра были получены на базе ортогональных проекций, без предположений о гауссовости ошибок измерений. Затем просто было показано, что для специального случая распределения ошибок по Гауссу фильтр дает точную оценку условной вероятности распределения состояния системы.
Наглядный пример возможностей фильтра — получение оптимальных, непрерывно обновляемых оценок положения и скорости некоторого объекта по результатам временно́го ряда неточных измерений его местоположения. Например, в радиолокации стоит задача сопровождения цели, определения её местоположения, скорости и ускорения, при этом результаты измерений поступают постепенно и сильно зашумлены. Фильтр Калмана использует вероятностную модель динамики цели, задающую тип вероятного движения объекта, что позволяет снизить воздействие шума и получить хорошие оценки положения объекта в настоящий, будущий или прошедший момент времени.

Введение
Фильтр Калмана оперирует понятием вектора состояния системы (набором параметров, описывающих состояние системы на некоторый момент времени) и его статистическим описанием. В общем случае динамика некоторого вектора состояния описывается плотностями вероятности распределения его компонент в каждый момент времени. При наличии определённой математической модели производимых наблюдений за системой, а также модели априорного изменения параметров вектора состояния (а именно — в качестве марковского формирующего процесса) можно записать уравнение для апостериорной плотности вероятности вектора состояния в любой момент времени. Данное дифференциальное уравнение носит название уравнение Стратоновича. Уравнение Стратоновича в общем виде не решается. Аналитическое решение удается получить только в случае ряда ограничений (предположений):

гауссовые априорные и апостериорные плотности вероятности вектора состояния на любой момент времени (в том числе начальный)
гауссовые формирующие шумы
гауссовые шумы наблюдений
белые шумы наблюдений
линейность модели наблюдений
линейность модели формирующего процесса (который, напомним, должен являться марковским процессом)Классический фильтр Калмана является уравнениями для расчета первого и второго момента апостериорной плотности вероятности (в смысле вектора математических ожиданий и матрицы дисперсий, в том числе взаимных) при данных ограничениях. Ввиду того, что для нормальной плотности вероятности математическое ожидание и дисперсионная матрица полностью задают плотность вероятности, можно сказать, что фильтр Калмана рассчитывает апостериорную плотность вероятности вектора состояния на каждый момент времени. А значит полностью описывает вектор состояния как случайную векторную величину.
Расчетные значения математических ожиданий при этом являются оптимальными оценками по критерию среднеквадратической ошибки, что и обуславливает его широкое применение.
Существует несколько разновидностей фильтра Калмана, отличающихся приближениями и ухищрениями, которые приходится применять для сведения фильтра к описанному виду и уменьшения его размерности:

расширенный фильтр Калмана (EKF, Extended Kalman filter). Сведение нелинейных моделей наблюдений и формирующего процесса с помощью линеаризации посредством разложения в ряд Тейлора;
сигма-точечный фильтр Калмана (UKF, Unscented Kalman filter). Используется в задачах, в которых простая линеаризация приводит к уничтожению полезных связей между компонентами вектора состояния. В этом случае «линеаризация» основана на сигма-точечном преобразовании;
Ensemble Kalman filter (EnKF). Используется для уменьшения размерности задачи;
возможны варианты с нелинейным дополнительным фильтром, позволяющим привести негауссовые наблюдения к нормальным;
возможны варианты с «обеляющим» фильтром, позволяющим работать с «цветными» шумами;
и т. д.Кроме того, имеются аналоги фильтра Калмана, использующие полностью или частично модель непрерывного времени:

фильтр Калмана — Бьюси, в котором и эволюция системы, и измерения имеют вид функций от непрерывного времени;
гибридный фильтр Калмана, использующий непрерывное время при описании эволюции системы, и дискретные моменты времени для измерений.

Исторический обзор и имена
Фильтр назван в честь венгерского математика Рудольфа Э. Калмана, эмигрировавшего в США. Хотя Торвальд Николай Тиле и Питер Сверлинг разработали подобный алгоритм раньше (Тиле рассмотрел лишь некоторую частную постановку, в то время как алгоритм Сверлинга практически идентичен калмановскому). Ричард С. Бьюси из Университета Южной Калифорнии сделал вклад в теорию, которая привела к так называемому фильтру Калмана — Бьюси. Стэнли Ф. Шмидт считается первым, кто реализовал фильтр Калмана во время визита Калмана в Исследовательский центр Эймса, так что Калман увидел применимость своих идей к задаче оценки траекторий для программы «Аполлон», что привело, в конечном счете, к включению этого фильтра в компьютерную систему навигации «Аполлона». Фильтр Калмана был впервые описан и частично разработан в работах Сверлинга (1958), Калмана (1960) и Калмана и Бьюси (1961).
Фильтры Калмана оказались критически важными для реализации навигационных систем подводных лодок ВМС США с ядерными баллистическими ракетами на борту, в навигационных системах крылатых ракет, например, «Томагавков». Он также использовался в навигационных и управляющих системах проекта НАСА «Спейс шаттл», используется в системах управления и навигации МКС.
Цифровой фильтр Калмана иногда называют фильтром Стратоновича — Калмана — Бьюси, поскольку, он является частным случаем более общего, нелинейного фильтра, разработанного несколько раньше советским математиком Р. Л. Стратоновичем. Фактически, некоторые из уравнений для частных случаев линейного фильтра появились в этих работах Стратоновича, опубликованных до лета 1960 года, когда Калман встретился со Стратоновичем во время конференции в Москве.

Используемая модель динамической системы
Фильтры Калмана базируются на дискретизированных по времени линейных динамических системах. Такие системы моделируются цепями Маркова при помощи линейных операторов и слагаемых с нормальным распределением. Состояние системы описывается вектором конечной размерности — вектором состояния. В каждый такт времени линейный оператор действует на вектор состояния и переводит его в другой вектор состояния (детерминированное изменение состояния), добавляется некоторый вектор нормального шума (случайные факторы) и в общем случае вектор управления, моделирующий воздействие системы управления. Фильтр Калмана можно рассматривать как аналог скрытым моделям Маркова, с тем отличием, что переменные, описывающие состояние системы, являются элементами бесконечного множества действительных чисел (в отличие от конечного множества пространства состояний в скрытых моделях Маркова). Кроме того, скрытые модели Маркова могут использовать произвольные распределения для последующих значений вектора состояния, в отличие от фильтра Калмана, использующего модель нормально распределенного шума. Существует строгая взаимосвязь между уравнениями фильтра Калмана и скрытой модели Маркова. Обзор этих и других моделей дан Roweis и Chahramani (1999).
При использовании фильтра Калмана для получения оценок вектора состояния процесса по серии зашумленных измерений необходимо представить модель данного процесса в соответствии со структурой фильтра — в виде матричного уравнения определённого типа. Для каждого такта k работы фильтра необходимо в соответствии с приведенным ниже описанием определить матрицы: эволюции процесса Fk; матрицу наблюдений Hk; ковариационную матрицу процесса Qk; ковариационную матрицу шума измерений Rk; при наличии управляющих воздействий — матрицу их коэффициентов Bk.

Модель системы/процесса подразумевает, что истинное состояние в момент k получается из истинного состояния в момент k−1 в соответствии с уравнением:

  
    
      
        
          
            
              x
            
          
          
            k
          
        
        =
        
          
            
              F
            
          
          
            k
          
        
        
          
            
              x
            
          
          
            k
            −
            1
          
        
        +
        
          
            
              B
            
          
          
            k
          
        
        
          
            
              u
            
          
          
            k
          
        
        +
        
          
            
              w
            
          
          
            k
          
        
      
    
    {\displaystyle {\textbf {x}}_{k}={\textbf {F}}_{k}{\textbf {x}}_{k-1}+{\textbf {B}}_{k}{\textbf {u}}_{k}+{\textbf {w}}_{k}}
  ,где

Fk — матрица эволюции процесса/системы, которая воздействует на вектор xk−1 (вектор состояния в момент k−1);
Bk — матрица управления, которая прикладывается к вектору управляющих воздействий uk;
wk — нормальный случайный процесс с нулевым математическим ожиданием и ковариационной матрицей Qk, который описывает случайный характер эволюции системы/процесса:
  
    
      
        
          
            
              w
            
          
          
            k
          
        
        ∼
        N
        (
        0
        ,
        
          
            
              Q
            
          
          
            k
          
        
        )
      
    
    {\displaystyle {\textbf {w}}_{k}\sim N(0,{\textbf {Q}}_{k})}
  В момент k производится наблюдение (измерение) zk истинного вектора состояния xk, которые связаны между собой уравнением:

  
    
      
        
          
            
              z
            
          
          
            k
          
        
        =
        
          
            
              H
            
          
          
            k
          
        
        
          
            
              x
            
          
          
            k
          
        
        +
        
          
            
              v
            
          
          
            k
          
        
      
    
    {\displaystyle {\textbf {z}}_{k}={\textbf {H}}_{k}{\textbf {x}}_{k}+{\textbf {v}}_{k}}
  где Hk — матрица измерений, связывающая истинный вектор состояния и вектор произведенных измерений, vk — белый гауссовский шум измерений с нулевым математическим ожиданием и ковариационной матрицей Rk:

  
    
      
        
          
            
              v
            
          
          
            k
          
        
        ∼
        N
        (
        0
        ,
        
          
            
              R
            
          
          
            k
          
        
        )
      
    
    {\displaystyle {\textbf {v}}_{k}\sim N(0,{\textbf {R}}_{k})}
  Начальное состояние и векторы случайных процессов на каждом такте {x0, w1, …, wk, v1, …, vk} считаются независимыми.
Многие реальные динамические системы нельзя точно описать данной моделью. На практике неучтённая в модели динамика может серьёзно испортить рабочие характеристики фильтра, особенно при работе с неизвестным стохастическим сигналом на входе. Более того, неучтённая в модели динамика может сделать фильтр неустойчивым. С другой стороны, независимый белый шум в качестве сигнала не будет приводить к расхождению алгоритма. Задача отделения шумов измерений от неучтенной в модели динамики сложна, решается она с помощью теории робастных систем управления.

Фильтр Калмана
Фильтр Калмана является разновидностью рекурсивных фильтров. Для вычисления оценки состояния системы на текущий такт работы ему необходима оценка состояния (в виде оценки состояния системы и оценки погрешности определения этого состояния) на предыдущем такте работы и измерения на текущем такте. Данное свойство отличает его от пакетных фильтров, требующих в текущий такт работы знание истории измерений и/или оценок. Далее под записью 
  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            n
            
              |
            
            m
          
        
      
    
    {\displaystyle {\hat {\textbf {x}}}_{n|m}}
   будем понимать оценку истинного вектора 
  
    
      
        
          
            x
          
        
      
    
    {\displaystyle {\textbf {x}}}
   в момент n с учетом измерений с момента начала работы и по момент m включительно.
Состояние фильтра задается двумя переменными:

  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
          
        
      
    
    {\displaystyle {\hat {\textbf {x}}}_{k|k}}
   — апостериорная оценка состояния объекта в момент k полученная по результатам наблюдений вплоть до момента k включительно (в русскоязычной литературе часто обозначается 
  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
          
        
      
    
    {\displaystyle {\hat {\textbf {x}}}_{k}}
  , где 
  
    
      
        
          
            
              
              ^
            
          
        
      
    
    {\displaystyle {\hat {}}}
   означает «оценка», а k — номер такта, на котором она получена);

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
      
    
    {\displaystyle {\textbf {P}}_{k|k}}
   — апостериорная ковариационная матрица ошибок, задающая оценку точности полученной оценки вектора состояния и включающая в себя оценку дисперсий погрешности вычисленного состояния и ковариации, показывающие выявленные взаимосвязи между параметрами состояния системы (в русскоязычной литературе часто обозначается 
  
    
      
        
          
            
              
                
                  D
                
                ^
              
            
          
          
            k
          
        
      
    
    {\displaystyle {\hat {\textbf {D}}}_{k}}
  ).Каждая итерация фильтра Калмана делится на две фазы: экстраполяция (прогноз) и коррекция. Во время экстраполяции фильтр получает предварительную оценку состояния системы 
  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
      
    
    {\displaystyle {\hat {\textbf {x}}}_{k|k-1}}
   (в русскоязычной литературе часто обозначается 
  
    
      
        
          
            
              
                
                  x
                
                ~
              
            
          
          
            k
          
        
      
    
    {\displaystyle {\tilde {\textbf {x}}}_{k}}
  , где 
  
    
      
        
          
            
              
              ~
            
          
        
      
    
    {\displaystyle {\tilde {}}}
   означает «экстраполяция», а k — номер такта, на котором она получена) на текущий шаг по итоговой оценке состояния с предыдущего шага (либо предварительную оценку на следующий такт по итоговой оценке текущего шага, в зависимости от интерпретации). Эту предварительную оценку также называют априорной оценкой состояния, так как для её получения не используются наблюдения соответствующего шага. В фазе коррекции априорная экстраполяция дополняется соответствующими текущими измерениями для коррекции оценки. Скорректированная оценка также называется апостериорной оценкой состояния, либо просто оценкой вектора состояния 
  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
          
        
      
    
    {\displaystyle {\hat {\textbf {x}}}_{k}}
  .
Обычно эти две фазы чередуются: экстраполяция производится по результатам коррекции до следующего наблюдения, а коррекция производится совместно с доступными на следующем шаге наблюдениями, и т. д. Однако возможно и другое развитие событий, если по некоторой причине наблюдение оказалось недоступным, то этап коррекции может быть пропущен и выполнена экстраполяция по нескорректированной оценке (априорной экстраполяции). Аналогично, если независимые измерения доступны только в отдельные такты работы, всё равно возможны коррекции (обычно с использованием другой матрицы наблюдений Hk).
Далее рассмотрим работу классического оптимального фильтра Калмана.

Этап экстраполяции
Этап коррекции
Выражение для ковариационной матрицы оценки вектора состояния системы справедливо только при использовании приведенного оптимального вектора коэффициентов. В общем случае это выражение имеет более сложный вид.

Инварианты
Если модель абсолютно точна и абсолютно точно заданы начальные условия 
  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            0
            
              |
            
            0
          
        
      
    
    {\displaystyle {\hat {\textbf {x}}}_{0|0}}
   и 
  
    
      
        
          
            
              P
            
          
          
            0
            
              |
            
            0
          
        
      
    
    {\displaystyle {\textbf {P}}_{0|0}}
  , то следующие величины сохраняются после любого количества итераций работы фильтра — являются инвариантами:
Математические ожидания оценок и экстраполяций вектора состояния системы, матрицы ошибок являются нуль-векторами:

  
    
      
        
          
            E
          
        
        [
        
          
            
              x
            
          
          
            k
          
        
        −
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
          
        
        ]
        =
        
          
            E
          
        
        [
        
          
            
              x
            
          
          
            k
          
        
        −
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        ]
        =
        0
      
    
    {\displaystyle {\textsf {E}}[{\textbf {x}}_{k}-{\hat {\textbf {x}}}_{k|k}]={\textsf {E}}[{\textbf {x}}_{k}-{\hat {\textbf {x}}}_{k|k-1}]=0}
  

  
    
      
        
          
            E
          
        
        [
        
          
            
              
                
                  y
                
                ~
              
            
          
          
            k
          
        
        ]
        =
        0
      
    
    {\displaystyle {\textsf {E}}[{\tilde {\textbf {y}}}_{k}]=0}
  где 
  
    
      
        
          
            E
          
        
        [
        ξ
        ]
      
    
    {\displaystyle {\textsf {E}}[\xi ]}
   — математическое ожидание 
  
    
      
        ξ
      
    
    {\displaystyle \xi }
  .
Расчетные матрицы ковариаций экстраполяций, оценок состояния системы и вектора ошибок совпадают с истинными матрицами ковариаций:

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
        =
        
          
            cov
          
        
        (
        
          
            
              x
            
          
          
            k
          
        
        −
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
          
        
        )
      
    
    {\displaystyle {\textbf {P}}_{k|k}={\textrm {cov}}({\textbf {x}}_{k}-{\hat {\textbf {x}}}_{k|k})}
  

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        =
        
          
            cov
          
        
        (
        
          
            
              x
            
          
          
            k
          
        
        −
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        )
      
    
    {\displaystyle {\textbf {P}}_{k|k-1}={\textrm {cov}}({\textbf {x}}_{k}-{\hat {\textbf {x}}}_{k|k-1})}
  

  
    
      
        
          
            
              S
            
          
          
            k
          
        
        =
        
          
            cov
          
        
        (
        
          
            
              
                
                  y
                
                ~
              
            
          
          
            k
          
        
        )
      
    
    {\displaystyle {\textbf {S}}_{k}={\textrm {cov}}({\tilde {\textbf {y}}}_{k})}

Пример построения фильтра
Представим себе вагонетку, стоящую на бесконечно длинных рельсах при отсутствии трения. Изначально она покоится в позиции 0, но под действием случайных факторов у неё возникает случайное ускорение. Мы измеряем положение вагонетки каждые ∆t секунд, но измерения неточны. Мы хотим получать оценки положения вагонетки и её скорости. Применим к этой задаче фильтр Калмана, определим все необходимые матрицы.
В данной задаче матрицы F, H, R и Q не зависят от времени, опустим их индексы.
Координата и скорость вагонетки описывается вектором в линейном пространстве состояний

  
    
      
        
          
            
              x
            
          
          
            k
          
        
        =
        
          
            [
            
              
                
                  x
                
              
              
                
                  
                    
                      
                        x
                        ˙
                      
                    
                  
                
              
            
            ]
          
        
      
    
    {\displaystyle {\textbf {x}}_{k}={\begin{bmatrix}x\\{\dot {x}}\end{bmatrix}}}
  где 
  
    
      
        
          
            
              x
              ˙
            
          
        
      
    
    {\displaystyle {\dot {x}}}
   — скорость (первая производная координаты 
  
    
      
        x
      
    
    {\displaystyle x}
   по времени).
Будем считать, что между (k−1)-м и k-м тактами вагонетка движется с постоянным ускорением ak, распределенным по нормальному закону с нулевым математическим ожиданием и среднеквадратическим отклонением σa. В соответствии с механикой Ньютона можно записать

  
    
      
        
          
            
              x
            
          
          
            k
          
        
        =
        
          
            F
          
        
        
          
            
              x
            
          
          
            k
            −
            1
          
        
        +
        
          
            G
          
        
        
          a
          
            k
          
        
      
    
    {\displaystyle {\textbf {x}}_{k}={\textbf {F}}{\textbf {x}}_{k-1}+{\textbf {G}}a_{k}}
  где

  
    
      
        
          
            F
          
        
        =
        
          
            [
            
              
                
                  1
                
                
                  Δ
                  t
                
              
              
                
                  0
                
                
                  1
                
              
            
            ]
          
        
      
    
    {\displaystyle {\textbf {F}}={\begin{bmatrix}1&\Delta t\\0&1\end{bmatrix}}}
  Матрица управления записывается в виде вектора

  
    
      
        
          
            G
          
        
        =
        
          
            [
            
              
                
                  
                    
                      
                        Δ
                        
                          t
                          
                            2
                          
                        
                      
                      2
                    
                  
                
              
              
                
                  Δ
                  t
                
              
            
            ]
          
        
      
    
    {\displaystyle {\textbf {G}}={\begin{bmatrix}{\frac {\Delta t^{2}}{2}}\\\Delta t\end{bmatrix}}}
  .Вектор управления вырождается в скаляр ak.
Ковариационная матрица случайных воздействий

  
    
      
        
          
            Q
          
        
        =
        
          
            cov
          
        
        (
        
          
            G
          
        
        a
        )
        =
        
          
            E
          
        
        [
        (
        
          
            G
          
        
        a
        )
        (
        
          
            G
          
        
        a
        
          )
          
            T
          
        
        ]
        =
        
          
            G
          
        
        
          
            E
          
        
        [
        
          a
          
            2
          
        
        ]
        
          
            
              G
            
          
          
            T
          
        
        =
        
          
            G
          
        
        [
        
          σ
          
            a
          
          
            2
          
        
        ]
        
          
            
              G
            
          
          
            T
          
        
        =
        
          σ
          
            a
          
          
            2
          
        
        
          
            G
          
        
        
          
            
              G
            
          
          
            T
          
        
      
    
    {\displaystyle {\textbf {Q}}={\textrm {cov}}({\textbf {G}}a)={\textsf {E}}[({\textbf {G}}a)({\textbf {G}}a)^{\text{T}}]={\textbf {G}}{\textsf {E}}[a^{2}]{\textbf {G}}^{\text{T}}={\textbf {G}}[\sigma _{a}^{2}]{\textbf {G}}^{\text{T}}=\sigma _{a}^{2}{\textbf {G}}{\textbf {G}}^{\text{T}}}
   (σa — скаляр).На каждом такте работы производится измерение положения вагонетки. Предположим, что погрешность измерений vk имеет нормальное распределение с нулевым математическим ожиданием и среднеквадратическим отклонением σz. Тогда

  
    
      
        
          
            
              z
            
          
          
            k
          
        
        =
        
          
            
              Hx
            
          
          
            k
          
        
        +
        
          
            
              v
            
          
          
            k
          
        
      
    
    {\displaystyle {\textbf {z}}_{k}={\textbf {Hx}}_{k}+{\textbf {v}}_{k}}
  где

  
    
      
        
          
            H
          
        
        =
        
          
            [
            
              
                
                  1
                
                
                  0
                
              
            
            ]
          
        
      
    
    {\displaystyle {\textbf {H}}={\begin{bmatrix}1&0\end{bmatrix}}}
  и ковариационная матрица шума наблюдений имеет вид

  
    
      
        
          
            R
          
        
        =
        
          
            E
          
        
        [
        
          
            
              v
            
          
          
            k
          
        
        
          
            
              v
            
          
          
            k
          
          
            T
          
        
        ]
        =
        
          
            [
            
              
                
                  
                    σ
                    
                      z
                    
                    
                      2
                    
                  
                
              
            
            ]
          
        
      
    
    {\displaystyle {\textbf {R}}={\textsf {E}}[{\textbf {v}}_{k}{\textbf {v}}_{k}^{\text{T}}]={\begin{bmatrix}\sigma _{z}^{2}\end{bmatrix}}}
  .Начальное положение вагонетки известно точно

  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            0
            
              |
            
            0
          
        
        =
        
          
            [
            
              
                
                  0
                
              
              
                
                  0
                
              
            
            ]
          
        
      
    
    {\displaystyle {\hat {\textbf {x}}}_{0|0}={\begin{bmatrix}0\\0\end{bmatrix}}}
  ,
  
    
      
        
          
            
              P
            
          
          
            0
            
              |
            
            0
          
        
        =
        
          
            [
            
              
                
                  0
                
                
                  0
                
              
              
                
                  0
                
                
                  0
                
              
            
            ]
          
        
      
    
    {\displaystyle {\textbf {P}}_{0|0}={\begin{bmatrix}0&0\\0&0\end{bmatrix}}}
  .Если же положение и скорость вагонетки известна лишь приблизительно, то можно инициализировать матрицу дисперсий достаточно большим числом L, чтобы это число превосходило дисперсию измерений координаты

  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            0
            
              |
            
            0
          
        
        =
        
          
            [
            
              
                
                  0
                
              
              
                
                  0
                
              
            
            ]
          
        
      
    
    {\displaystyle {\hat {\textbf {x}}}_{0|0}={\begin{bmatrix}0\\0\end{bmatrix}}}
  ,
  
    
      
        
          
            
              P
            
          
          
            0
            
              |
            
            0
          
        
        =
        
          
            [
            
              
                
                  L
                
                
                  0
                
              
              
                
                  0
                
                
                  L
                
              
            
            ]
          
        
      
    
    {\displaystyle {\textbf {P}}_{0|0}={\begin{bmatrix}L&0\\0&L\end{bmatrix}}}
  .В этом случае на первых тактах работы фильтр будет с бо́льшим весом использовать результаты измерений, чем имеющуюся априорную информацию.

Вывод формул
Ковариационная матрица оценки вектора состояния
По определению ковариационной матрицы Pk|k

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
        =
        
          
            cov
          
        
        (
        
          
            
              x
            
          
          
            k
          
        
        −
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
          
        
        )
      
    
    {\displaystyle {\textbf {P}}_{k|k}={\textrm {cov}}({\textbf {x}}_{k}-{\hat {\textbf {x}}}_{k|k})}
  подставляем выражение для оценки вектора состояния 
  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
          
        
      
    
    {\displaystyle {\hat {\textbf {x}}}_{k|k}}
  

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
        =
        
          
            cov
          
        
        (
        
          
            
              x
            
          
          
            k
          
        
        −
        (
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        +
        
          
            
              K
            
          
          
            k
          
        
        
          
            
              
                
                  y
                
                ~
              
            
          
          
            k
          
        
        )
        )
      
    
    {\displaystyle {\textbf {P}}_{k|k}={\textrm {cov}}({\textbf {x}}_{k}-({\hat {\textbf {x}}}_{k|k-1}+{\textbf {K}}_{k}{\tilde {\textbf {y}}}_{k}))}
  и расписываем выражение для вектора ошибок 
  
    
      
        
          
            
              
                
                  y
                
                ~
              
            
          
          
            k
          
        
      
    
    {\displaystyle {\tilde {\textbf {y}}}_{k}}
  

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
        =
        
          
            cov
          
        
        (
        
          
            
              x
            
          
          
            k
          
        
        −
        (
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        +
        
          
            
              K
            
          
          
            k
          
        
        (
        
          
            
              z
            
          
          
            k
          
        
        −
        
          
            
              H
            
          
          
            k
          
        
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        )
        )
        )
      
    
    {\displaystyle {\textbf {P}}_{k|k}={\textrm {cov}}({\textbf {x}}_{k}-({\hat {\textbf {x}}}_{k|k-1}+{\textbf {K}}_{k}({\textbf {z}}_{k}-{\textbf {H}}_{k}{\hat {\textbf {x}}}_{k|k-1})))}
  и вектора измерений 
  
    
      
        
          
            
              z
            
          
          
            k
          
        
      
    
    {\displaystyle {\textbf {z}}_{k}}
  

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
        =
        
          
            cov
          
        
        (
        
          
            
              x
            
          
          
            k
          
        
        −
        (
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        +
        
          
            
              K
            
          
          
            k
          
        
        (
        
          
            
              H
            
          
          
            k
          
        
        
          
            
              x
            
          
          
            k
          
        
        +
        
          
            
              v
            
          
          
            k
          
        
        −
        
          
            
              H
            
          
          
            k
          
        
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        )
        )
        )
      
    
    {\displaystyle {\textbf {P}}_{k|k}={\textrm {cov}}({\textbf {x}}_{k}-({\hat {\textbf {x}}}_{k|k-1}+{\textbf {K}}_{k}({\textbf {H}}_{k}{\textbf {x}}_{k}+{\textbf {v}}_{k}-{\textbf {H}}_{k}{\hat {\textbf {x}}}_{k|k-1})))}
  выносим вектор погрешности измерений vk

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
        =
        
          
            cov
          
        
        (
        (
        I
        −
        
          
            
              K
            
          
          
            k
          
        
        
          
            
              H
            
          
          
            k
          
        
        )
        (
        
          
            
              x
            
          
          
            k
          
        
        −
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        )
        −
        
          
            
              K
            
          
          
            k
          
        
        
          
            
              v
            
          
          
            k
          
        
        )
      
    
    {\displaystyle {\textbf {P}}_{k|k}={\textrm {cov}}((I-{\textbf {K}}_{k}{\textbf {H}}_{k})({\textbf {x}}_{k}-{\hat {\textbf {x}}}_{k|k-1})-{\textbf {K}}_{k}{\textbf {v}}_{k})}
  так как вектор погрешности измерений vk не коррелирован с другими аргументами, получаем выражение

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
        =
        
          
            cov
          
        
        (
        (
        I
        −
        
          
            
              K
            
          
          
            k
          
        
        
          
            
              H
            
          
          
            k
          
        
        )
        (
        
          
            
              x
            
          
          
            k
          
        
        −
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        )
        )
        +
        
          
            cov
          
        
        (
        
          
            
              K
            
          
          
            k
          
        
        
          
            
              v
            
          
          
            k
          
        
        )
      
    
    {\displaystyle {\textbf {P}}_{k|k}={\textrm {cov}}((I-{\textbf {K}}_{k}{\textbf {H}}_{k})({\textbf {x}}_{k}-{\hat {\textbf {x}}}_{k|k-1}))+{\textrm {cov}}({\textbf {K}}_{k}{\textbf {v}}_{k})}
  в соответствии со свойствами ковариации векторов данное выражение преобразуется к виду

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
        =
        (
        I
        −
        
          
            
              K
            
          
          
            k
          
        
        
          
            
              H
            
          
          
            k
          
        
        )
        
          
            cov
          
        
        (
        
          
            
              x
            
          
          
            k
          
        
        −
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        )
        (
        I
        −
        
          
            
              K
            
          
          
            k
          
        
        
          
            
              H
            
          
          
            k
          
        
        
          )
          
            T
          
        
        +
        
          
            
              K
            
          
          
            k
          
        
        
          
            cov
          
        
        (
        
          
            
              v
            
          
          
            k
          
        
        )
        
          
            
              K
            
          
          
            k
          
          
            T
          
        
      
    
    {\displaystyle {\textbf {P}}_{k|k}=(I-{\textbf {K}}_{k}{\textbf {H}}_{k}){\textrm {cov}}({\textbf {x}}_{k}-{\hat {\textbf {x}}}_{k|k-1})(I-{\textbf {K}}_{k}{\textbf {H}}_{k})^{\text{T}}+{\textbf {K}}_{k}{\textrm {cov}}({\textbf {v}}_{k}){\textbf {K}}_{k}^{\text{T}}}
  заменяя выражение для ковариационной матрицы экстраполяции вектора состояния на Pk|k−1 и определение ковариационной матрицы шумов наблюдений на Rk, получаем

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
        =
        (
        I
        −
        
          
            
              K
            
          
          
            k
          
        
        
          
            
              H
            
          
          
            k
          
        
        )
        
          
            
              P
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        (
        I
        −
        
          
            
              K
            
          
          
            k
          
        
        
          
            
              H
            
          
          
            k
          
        
        
          )
          
            T
          
        
        +
        
          
            
              K
            
          
          
            k
          
        
        
          
            
              R
            
          
          
            k
          
        
        
          
            
              K
            
          
          
            k
          
          
            T
          
        
      
    
    {\displaystyle {\textbf {P}}_{k|k}=(I-{\textbf {K}}_{k}{\textbf {H}}_{k}){\textbf {P}}_{k|k-1}(I-{\textbf {K}}_{k}{\textbf {H}}_{k})^{\text{T}}+{\textbf {K}}_{k}{\textbf {R}}_{k}{\textbf {K}}_{k}^{\text{T}}}
  Полученное выражение справедливо для произвольной матрицы коэффициентов, но если в качестве неё выступает матрица коэффициентов, оптимальная по Калману, то данное выражение для ковариационной матрицы можно упростить.

Оптимальная матрица коэффициентов усиления
Фильтр Калмана минимизирует сумму квадратов математических ожиданий ошибок оценки вектора состояния.
Вектор ошибки оценки вектора состояния

  
    
      
        
          
            
              x
            
          
          
            k
          
        
        −
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
          
        
      
    
    {\displaystyle {\textbf {x}}_{k}-{\hat {\textbf {x}}}_{k|k}}
  Стоит задача минимизировать сумму математических ожиданий квадратов компонент данного вектора

  
    
      
        
          
            E
          
        
        [
        
        
          |
        
        
          
            
              x
            
          
          
            k
          
        
        −
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            
              |
            
            k
          
        
        
          
            |
          
          
            2
          
        
        
        ]
      
    
    {\displaystyle {\textsf {E}}[\;|{\textbf {x}}_{k}-{\hat {\textbf {x}}}_{k|k}|^{2}\,]}
  ,что эквивалентно минимизации следа ковариационной матрицы оценки вектора состояния Pk|k. Подставим в выражение для ковариационной матрицы оценки вектора состояния имеющиеся выражения и дополним до полного квадрата:

Заметим, что последнее слагаемое является ковариационной матрицей некоторой случайной величины, поэтому его след неотрицателен. Минимум следа достигнется при обнулении последнего слагаемого:

  
    
      
        
          
            
              K
            
          
          
            k
          
        
        =
        
          
            
              P
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        
          
            
              H
            
          
          
            k
          
          
            T
          
        
        
          
            
              S
            
          
          
            k
          
          
            −
            1
          
        
      
    
    {\displaystyle {\textbf {K}}_{k}={\textbf {P}}_{k|k-1}{\textbf {H}}_{k}^{\text{T}}{\textbf {S}}_{k}^{-1}}
  Утверждается, что данная матрица является искомой и при использовании в качестве матрицы коэффициентов в фильтре Калмана минимизирует сумму средних квадратов ошибок оценки вектора состояния.

Ковариационная матрица оценки вектора состояния при использовании оптимальной матрицы коэффициентов
Выражение для ковариационной матрицы оценки вектора состояния Pk|k при использовании оптимальной матрицы коэффициентов примет вид:

  
    
      
        
          
            
              P
            
          
          
            k
            
              |
            
            k
          
        
        =
        
          
            
              P
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        −
        
          
            
              P
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
        
          
            
              H
            
          
          
            k
          
          
            T
          
        
        
          
            
              S
            
          
          
            k
          
          
            −
            1
          
        
        
          
            
              H
            
          
          
            k
          
        
        
          
            
              P
            
          
          
            k
            
              |
            
            k
            −
            1
          
        
      
    
    {\displaystyle {\textbf {P}}_{k|k}={\textbf {P}}_{k|k-1}-{\textbf {P}}_{k|k-1}{\textbf {H}}_{k}^{\text{T}}{\textbf {S}}_{k}^{-1}{\textbf {H}}_{k}{\textbf {P}}_{k|k-1}}
  

Данная формула вычислительно проще и поэтому практически всегда используется на практике, но она корректна только при использовании оптимальной матрицы коэффициентов. Если ввиду малой вычислительной точности возникает проблема с вычислительной устойчивостью, либо специально используется матрица коэффициентов, отличная от оптимальной, следует использовать общую формулу для ковариационной матрицы оценки вектора состояния.

Фильтр Калмана — Бюси
Фильтр Калмана — Бюси (названный по имени Ричарда Сноудена Бюси) — версия фильтра Калмана для непрерывного времени, опирается на следующую непрерывную динамическую модель состояния:

  
    
      
        
          
            d
            
              d
              t
            
          
        
        
          x
        
        (
        t
        )
        =
        
          F
        
        (
        t
        )
        
          x
        
        (
        t
        )
        +
        
          B
        
        (
        t
        )
        
          u
        
        (
        t
        )
        +
        
          w
        
        (
        t
        )
      
    
    {\displaystyle {\frac {d}{dt}}\mathbf {x} (t)=\mathbf {F} (t)\mathbf {x} (t)+\mathbf {B} (t)\mathbf {u} (t)+\mathbf {w} (t)}
  
  
    
      
        
          z
        
        (
        t
        )
        =
        
          H
        
        (
        t
        )
        
          x
        
        (
        t
        )
        +
        
          v
        
        (
        t
        )
      
    
    {\displaystyle \mathbf {z} (t)=\mathbf {H} (t)\mathbf {x} (t)+\mathbf {v} (t)}
  здесь 
  
    
      
        
          Q
        
        (
        t
        )
      
    
    {\displaystyle \mathbf {Q} (t)}
   и 
  
    
      
        
          R
        
        (
        t
        )
      
    
    {\displaystyle \mathbf {R} (t)}
   будут представлять интенсивности двух членов (с характеристиками белого шума) 
  
    
      
        
          w
        
        (
        t
        )
      
    
    {\displaystyle \mathbf {w} (t)}
   и 
  
    
      
        
          v
        
        (
        t
        )
      
    
    {\displaystyle \mathbf {v} (t)}
  , соответственно.
Фильтр состоит из двух дифференциальных уравнений, одно из которых служит для оценки состояния системы, а другое для оценки ковариации:

  
    
      
        
          
            d
            
              d
              t
            
          
        
        
          
            
              
                x
              
              ^
            
          
        
        (
        t
        )
        =
        
          F
        
        (
        t
        )
        
          
            
              
                x
              
              ^
            
          
        
        (
        t
        )
        +
        
          B
        
        (
        t
        )
        
          u
        
        (
        t
        )
        +
        
          K
        
        (
        t
        )
        (
        
          z
        
        (
        t
        )
        −
        
          H
        
        (
        t
        )
        
          
            
              
                x
              
              ^
            
          
        
        (
        t
        )
        )
      
    
    {\displaystyle {\frac {d}{dt}}{\hat {\mathbf {x} }}(t)=\mathbf {F} (t){\hat {\mathbf {x} }}(t)+\mathbf {B} (t)\mathbf {u} (t)+\mathbf {K} (t)(\mathbf {z} (t)-\mathbf {H} (t){\hat {\mathbf {x} }}(t))}
  
  
    
      
        
          
            d
            
              d
              t
            
          
        
        
          P
        
        (
        t
        )
        =
        
          F
        
        (
        t
        )
        
          P
        
        (
        t
        )
        +
        
          P
        
        (
        t
        )
        
          
            F
          
          
            T
          
        
        (
        t
        )
        +
        
          Q
        
        (
        t
        )
        −
        
          K
        
        (
        t
        )
        
          R
        
        (
        t
        )
        
          
            K
          
          
            T
          
        
        (
        t
        )
      
    
    {\displaystyle {\frac {d}{dt}}\mathbf {P} (t)=\mathbf {F} (t)\mathbf {P} (t)+\mathbf {P} (t)\mathbf {F} ^{T}(t)+\mathbf {Q} (t)-\mathbf {K} (t)\mathbf {R} (t)\mathbf {K} ^{T}(t)}
  где коэффициент Калмана получается по формуле

  
    
      
        
          K
        
        (
        t
        )
        =
        
          P
        
        (
        t
        )
        
          
            H
          
          
            T
          
        
        (
        t
        )
        
          
            R
          
          
            −
            1
          
        
        (
        t
        )
      
    
    {\displaystyle \mathbf {K} (t)=\mathbf {P} (t)\mathbf {H} ^{T}(t)\mathbf {R} ^{-1}(t)}
  Отметим, что в выражении для 
  
    
      
        
          K
        
        (
        t
        )
      
    
    {\displaystyle \mathbf {K} (t)}
   ковариация шумов наблюдения 
  
    
      
        
          R
        
        (
        t
        )
      
    
    {\displaystyle \mathbf {R} (t)}
   представляет одновременно ковариацию ошибки предсказания 
  
    
      
        
          
            
              
                y
              
              ~
            
          
        
        (
        t
        )
        =
        
          z
        
        (
        t
        )
        −
        
          H
        
        (
        t
        )
        
          
            
              
                x
              
              ^
            
          
        
        (
        t
        )
      
    
    {\displaystyle {\tilde {\mathbf {y} }}(t)=\mathbf {z} (t)-\mathbf {H} (t){\hat {\mathbf {x} }}(t)}
  ; причем эти ковариации равны только для случая непрерывного времени.Различие между шагами прогноза и коррекции в дискретной калмановской фильтрации не имеет места для непрерывного случая.
Второе дифференциальное уравнение для ковариации — это пример уравнения Риккати.

Гибридный фильтр Калмана
Большинство физических систем имеют модель непрерывного времени для эволюции состояния системы, и модель дискретных измерений для уточнения состояния. Поэтому модель фильтра может быть представлена так:

  
    
      
        
          
            
              
                
                  
                    
                      
                        x
                      
                      ˙
                    
                  
                
                (
                t
                )
              
              
                
                =
                
                  F
                
                (
                t
                )
                
                  x
                
                (
                t
                )
                +
                
                  B
                
                (
                t
                )
                
                  u
                
                (
                t
                )
                +
                
                  w
                
                (
                t
                )
                ,
              
              
                
                  w
                
                (
                t
                )
              
              
                
                ∼
                N
                
                  
                    (
                  
                
                
                  0
                
                ,
                
                  Q
                
                (
                t
                )
                
                  
                    )
                  
                
              
            
            
              
                
                  
                    z
                  
                  
                    k
                  
                
              
              
                
                =
                
                  
                    H
                  
                  
                    k
                  
                
                
                  
                    x
                  
                  
                    k
                  
                
                +
                
                  
                    v
                  
                  
                    k
                  
                
                ,
              
              
                
                  
                    v
                  
                  
                    k
                  
                
              
              
                
                ∼
                N
                (
                
                  0
                
                ,
                
                  
                    R
                  
                  
                    k
                  
                
                )
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}{\dot {\mathbf {x} }}(t)&=\mathbf {F} (t)\mathbf {x} (t)+\mathbf {B} (t)\mathbf {u} (t)+\mathbf {w} (t),&\mathbf {w} (t)&\sim N{\bigl (}\mathbf {0} ,\mathbf {Q} (t){\bigr )}\\\mathbf {z} _{k}&=\mathbf {H} _{k}\mathbf {x} _{k}+\mathbf {v} _{k},&\mathbf {v} _{k}&\sim N(\mathbf {0} ,\mathbf {R} _{k})\end{aligned}}}
  где

  
    
      
        
          
            x
          
          
            k
          
        
        =
        
          x
        
        (
        
          t
          
            k
          
        
        )
      
    
    {\displaystyle \mathbf {x} _{k}=\mathbf {x} (t_{k})}
  .Инициализация

  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            0
            ∣
            0
          
        
        =
        E
        
          
            [
          
        
        
          x
        
        (
        
          t
          
            0
          
        
        )
        
          
            ]
          
        
        ,
        
          
            P
          
          
            0
            ∣
            0
          
        
        =
        V
        a
        r
        
          
            [
          
        
        
          x
        
        (
        
          t
          
            0
          
        
        )
        
          
            ]
          
        
      
    
    {\displaystyle {\hat {\mathbf {x} }}_{0\mid 0}=E{\bigl [}\mathbf {x} (t_{0}){\bigr ]},\mathbf {P} _{0\mid 0}=Var{\bigl [}\mathbf {x} (t_{0}){\bigr ]}}
  
Прогноз

  
    
      
        
          
            
              
              
                
                  
                    
                      
                        
                          
                            x
                          
                          ^
                        
                      
                      ˙
                    
                  
                
                (
                t
                )
                =
                
                  F
                
                (
                t
                )
                
                  
                    
                      
                        x
                      
                      ^
                    
                  
                
                (
                t
                )
                +
                
                  B
                
                (
                t
                )
                
                  u
                
                (
                t
                )
                
                  , where 
                
                
                  
                    
                      
                        x
                      
                      ^
                    
                  
                
                (
                
                  t
                  
                    k
                    −
                    1
                  
                
                )
                =
                
                  
                    
                      
                        
                          x
                        
                        ^
                      
                    
                  
                  
                    k
                    −
                    1
                    ∣
                    k
                    −
                    1
                  
                
              
            
            
              
                ⇒
              
              
                
                  
                    
                      
                        
                          x
                        
                        ^
                      
                    
                  
                  
                    k
                    ∣
                    k
                    −
                    1
                  
                
                =
                
                  
                    
                      
                        x
                      
                      ^
                    
                  
                
                (
                
                  t
                  
                    k
                  
                
                )
              
            
            
              
              
                
                  
                    
                      
                        P
                      
                      ˙
                    
                  
                
                (
                t
                )
                =
                
                  F
                
                (
                t
                )
                
                  P
                
                (
                t
                )
                +
                
                  P
                
                (
                t
                )
                
                  F
                
                (
                t
                
                  )
                  
                    T
                  
                
                +
                
                  Q
                
                (
                t
                )
                
                  , where 
                
                
                  P
                
                (
                
                  t
                  
                    k
                    −
                    1
                  
                
                )
                =
                
                  
                    P
                  
                  
                    k
                    −
                    1
                    ∣
                    k
                    −
                    1
                  
                
              
            
            
              
                ⇒
              
              
                
                  
                    P
                  
                  
                    k
                    ∣
                    k
                    −
                    1
                  
                
                =
                
                  P
                
                (
                
                  t
                  
                    k
                  
                
                )
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}&{\dot {\hat {\mathbf {x} }}}(t)=\mathbf {F} (t){\hat {\mathbf {x} }}(t)+\mathbf {B} (t)\mathbf {u} (t){\text{, where }}{\hat {\mathbf {x} }}(t_{k-1})={\hat {\mathbf {x} }}_{k-1\mid k-1}\\\Rightarrow &{\hat {\mathbf {x} }}_{k\mid k-1}={\hat {\mathbf {x} }}(t_{k})\\&{\dot {\mathbf {P} }}(t)=\mathbf {F} (t)\mathbf {P} (t)+\mathbf {P} (t)\mathbf {F} (t)^{T}+\mathbf {Q} (t){\text{, where }}\mathbf {P} (t_{k-1})=\mathbf {P} _{k-1\mid k-1}\\\Rightarrow &\mathbf {P} _{k\mid k-1}=\mathbf {P} (t_{k})\end{aligned}}}
  Уравнения прогноза взяты из фильтра Калмана-Бюси с непрерывным временем, при 
  
    
      
        
          K
        
        (
        t
        )
        =
        0
      
    
    {\displaystyle \mathbf {K} (t)=0}
  . Прогноз состояния и ковариации получается интегрированием дифференциальных уравнений с начальным значением, взятым из предыдущего шага коррекции.

Коррекция

  
    
      
        
          
            K
          
          
            k
          
        
        =
        
          
            P
          
          
            k
            ∣
            k
            −
            1
          
        
        
          
            H
          
          
            k
          
          
            T
          
        
        
          
            (
          
        
        
          
            H
          
          
            k
          
        
        
          
            P
          
          
            k
            ∣
            k
            −
            1
          
        
        
          
            H
          
          
            k
          
          
            T
          
        
        +
        
          
            R
          
          
            k
          
        
        
          
            
              )
            
          
          
            −
            1
          
        
      
    
    {\displaystyle \mathbf {K} _{k}=\mathbf {P} _{k\mid k-1}\mathbf {H} _{k}^{T}{\bigl (}\mathbf {H} _{k}\mathbf {P} _{k\mid k-1}\mathbf {H} _{k}^{T}+\mathbf {R} _{k}{\bigr )}^{-1}}
  

  
    
      
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            ∣
            k
          
        
        =
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            ∣
            k
            −
            1
          
        
        +
        
          
            K
          
          
            k
          
        
        (
        
          
            z
          
          
            k
          
        
        −
        
          
            H
          
          
            k
          
        
        
          
            
              
                
                  x
                
                ^
              
            
          
          
            k
            ∣
            k
            −
            1
          
        
        )
      
    
    {\displaystyle {\hat {\mathbf {x} }}_{k\mid k}={\hat {\mathbf {x} }}_{k\mid k-1}+\mathbf {K} _{k}(\mathbf {z} _{k}-\mathbf {H} _{k}{\hat {\mathbf {x} }}_{k\mid k-1})}
  

  
    
      
        
          
            P
          
          
            k
            ∣
            k
          
        
        =
        (
        
          I
        
        −
        
          
            K
          
          
            k
          
        
        
          
            H
          
          
            k
          
        
        )
        
          
            P
          
          
            k
            ∣
            k
            −
            1
          
        
      
    
    {\displaystyle \mathbf {P} _{k\mid k}=(\mathbf {I} -\mathbf {K} _{k}\mathbf {H} _{k})\mathbf {P} _{k\mid k-1}}
  Уравнения коррекции идентичны уравнениям из дискретного фильтра Калмана.

Критика фильтра Калмана
На настоящий момент основная критика фильтра Калмана ведётся по следующим направлениям:

В фильтре Калмана погрешности представлены белым шумом, которого на самом деле в природе не существует.
Нет соответствия необходимому и достаточному условию оптимальности
  
    
      
        
          
            M
          
        
        [
        ε
        (
        t
        )
        
        
          
            
              Z
            
          
          
            k
          
        
        
          ]
          
            T
          
        
        =
        0
      
    
    {\displaystyle {\textsf {M}}[\varepsilon (t)\,{\textbf {Z}}_{k}]^{\text{T}}=0}
  00 при 00
  
    
      
        
          
            
              t
            
          
          
            0
          
        
        ≤
        τ
        ≤
        t
      
    
    {\displaystyle {\textbf {t}}_{0}\leq \tau \leq t}
  Ошибка в выводе фильтра Калмана — требуются противоречивые условия верности разных уравнений алгоритма: в одних чтобы τ < t и в других τ = t.Соответственно, позиция сторонников оптимальности данного фильтра заключается в том, что:

Возможно составить модифицированый фильтр Калмана, у которого погрешности будут представлены цветным шумом.
Использование условия оптимальности 
  
    
      
        
          
            M
          
        
        [
        ε
        (
        t
        )
        
        
          
            
              Z
            
          
          
            k
          
        
        
          ]
          
            T
          
        
        =
        0
        
      
    
    {\displaystyle {\textsf {M}}[\varepsilon (t)\,{\textbf {Z}}_{k}]^{\text{T}}=0\quad }
   в определённых случаях приводит к менее точному результату, нежели используемое в фильтре Калмана.
При выводе фильтра Калмана можно принять условия: τ < t, τ → t, что устраняет противоречие.

Где используется
Курсовертикали
Автопилот
Навигационные системы:
Инерциальные
Рельефометрические (по цифровым картам местности)
Спутниковые

См. также
Теорема Марельея

Литература и публикации
Фильтр Калмана
Перевод статьи «Kalman Filter»
«Фильтр Калмана для „чайников“: матрица наблюдаемости и фундаментальная матрица»
Peter Joseph «INTRODUCTORY LESSON: The one-dimensional Kalman Filter»
Перов, А. И. Статистическая теория радиотехнических систем. — М.: Радиотехника, 2003. — 400 с. — ISBN 5-93108-047-3.
Цыплаков, А. (2011) Введение в моделирование в пространстве состояний. — Квантиль, № 9, стр. 1—24.


== Примечания ==