То́кен (англ. token) — объект, создающийся из лексемы в процессе лексического анализа («токенизации», от англ. tokenizing).
В прикладном программировании понятие токена и его лексема могут не различаться.
Шаблон токена — формальное описание класса лексем, которые могут создать данный тип токена.